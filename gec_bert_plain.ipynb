{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline GEC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "PLATFORM='LOCAL' # 'GCP' or 'AWS' or 'LOCAL'\n",
    "\n",
    "# Disable HuggingFace's parallel tokenization feature to avoid any deadlock with our small dataset.\n",
    "# %env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCP specific setup.\n",
    "if PLATFORM == 'GCP':\n",
    "    # Connect to google drive\n",
    "    # from google.colab import drive\n",
    "    # drive.mount('/content/drive')\n",
    "\n",
    "    # Clone repo and install required libraries\n",
    "    !git clone https://ram-senth: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@github.com/team-langbot/model_gec.git\n",
    "\n",
    "    # !git checkout -b model origin/model\n",
    "\n",
    "!git config --global user.email \"ram.senth@berkeley.edu\"\n",
    "!git config --global user.name \"Ram S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/model_gec\n",
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "\n",
    "!pip freeze | grep tensorflow\n",
    "!pip freeze | grep sentencepiece\n",
    "!pip freeze | grep transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import sentencepiece\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel, T5Tokenizer, TFT5ForConditionalGeneration\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training config file cfgs/beto_2classes_plain.py\n",
      "Class ids: {'article': 'a', 'gender agreement': 'ga', 'gender and number agreement': 'gna', 'number agreement': 'na'}\n",
      "debug is enabled? False\n",
      "Is GPU enabled? True\n",
      "Dataset files: \n",
      "processed_data/bert_train_two_classed_plain.csv\n",
      "processed_data/bert_dev_two_classed_plain.csv\n",
      "processed_data/bert_test_two_classed_plain.csv\n",
      "Training label list: ['B-ga', 'I-ga', 'B-na', 'I-na', 'O']\n",
      "Model: dccuchile/bert-base-spanish-wwm-uncased\n",
      "Experiment: beto_cows_l2h_two_classes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from utils import Config, Training_config\n",
    "import torch\n",
    "import wandb\n",
    "from seqeval.metrics import accuracy_score\n",
    "from ner import NERModel\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "# Change this to True to train on GPU.\n",
    "DEBUG = False\n",
    "WANDB_PROJECT_NAME = \"langbot_gec\"\n",
    "ECC_TRAIN_CONFIG = 'cfgs/beto_2classes_plain.py'\n",
    "# ECC_TRAIN_CONFIG = 'cfgs/mBERT_2classes.py'\n",
    "\n",
    "main_args = Config()\n",
    "train_args = Training_config(ECC_TRAIN_CONFIG)\n",
    "\n",
    "if PLATFORM == 'local':\n",
    "    train_args.use_cuda = False\n",
    "train_args.debug = DEBUG\n",
    "\n",
    "def test_config():\n",
    "    print(f'Training config file {ECC_TRAIN_CONFIG}')\n",
    "    print(f'Class ids: {main_args.CLASS_IDS}')\n",
    "    print(f'debug is enabled? {train_args.debug}')\n",
    "    print(f'Is GPU enabled? {train_args.use_cuda}')\n",
    "    files = \"\\n\".join(train_args.train_dev_data)\n",
    "    print(f'Dataset files: \\n{files}')\n",
    "    print(f'Training label list: {train_args.labels_list}')\n",
    "    print(f'Model: {train_args.model_name}')\n",
    "    print(f'Experiment: {train_args.exp_name}')\n",
    "\n",
    "test_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some key parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = main_args.PROCESSED_DATA_FOLDER\n",
    "  # path to ner_dataset.csv file , from \n",
    "\n",
    "now = datetime.now() # curren\n",
    "\n",
    "def custom_acc_orig_non_other_tokens(y_true, y_pred):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    calculate loss dfunction explicitly filtering out also the 'Other'- labels\n",
    "\n",
    "    \n",
    "\n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "\n",
    "    \n",
    "\n",
    "    returns: accuracy\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    #get labels and predictions\n",
    "\n",
    "    \n",
    "\n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "\n",
    "\n",
    "# make sure that the paths are accessible within the notebook\n",
    "sys.path.insert(0,data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we will need to do quite a bit of pre-processing. BERT - as well as NER in general - requires us to process the text in a larger context, which suggests that we should send the data to BERT sentence-by-sentence. (An alternative would also be to just chunk up the text, irrespective of sentence boundaries.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Preprocessing <a id=\"preprocess\" />\n",
    "\n",
    "### III.1 BERT Tokenizer & BERT as a Black Box<a id=\"tokenizer\" />\n",
    "\n",
    "We need to define the tokenizer. BERT has its own and that is the one that should be used. As it is specific to the (pre-trained) model, we need to specify it. For obvious reasons we will use the 'cased'  model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(train_args.model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play with the tokenizer. You will see that the tokenizer occasionally splits one word into multiple tokens. Why is that the case? Because the approach of using word pieces reduces the vocabulary size and/or number of unknown words.\n",
    "\n",
    "Here is one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sí', ',', 'necesito', 'comprar', 'uno', 'chaqueta', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Sí, necesito comprar uno chaqueta.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['esta',\n",
       " 'oración',\n",
       " 'es',\n",
       " 'simple',\n",
       " 'y',\n",
       " 'utiliza',\n",
       " 'un',\n",
       " 'buen',\n",
       " 'conjunto',\n",
       " 'de',\n",
       " 'datos']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Esta oración es simple y utiliza un buen conjunto de datos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 1202, 1028, 3476, 5]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('Esto es facil')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the \"I'll\" phrase and the number '12342' got split. This already highlights an area one needs to address: splitting of tokens will need to be accounted for in the labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 1028, 3476, 5]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids([\n",
    "    '[CLS]', 'Esto', 'es', 'facil', '[SEP]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['facil']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([3476])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Now we are ready to use it for our text. \n",
    "\n",
    "But before we generate the model input data, let us first highlight also the BERT basics.\n",
    "\n",
    "We start by defining a BERT model that is created from one of the pre-trained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 21:26:17.449623: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-20 21:26:17.449885: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Some layers from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing TFBertModel: ['mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert/pooler/dense/bias:0', 'bert/pooler/dense/kernel:0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<transformers.models.bert.modeling_tf_bert.TFBertMainLayer at 0x144dc3430>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = TFBertModel.from_pretrained(train_args.model_name)\n",
    "bert.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us look at the weights in 'the' main layer. There are actually many layers in BERT. It starts with its own embeddings and goes through various other layers (discussed in detail in next week's live sessions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert.layers[0].weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Off.. that's a lot of 'layers'. Let's look at the names and dimensions of the first 11 layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Layer name: \t tf_bert_model/bert/embeddings/word_embeddings/weight:0\n",
      "Layer shape: \t (31002, 768)\n",
      "1\n",
      "Layer name: \t tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0\n",
      "Layer shape: \t (2, 768)\n",
      "2\n",
      "Layer name: \t tf_bert_model/bert/embeddings/position_embeddings/embeddings:0\n",
      "Layer shape: \t (512, 768)\n",
      "3\n",
      "Layer name: \t tf_bert_model/bert/embeddings/LayerNorm/gamma:0\n",
      "Layer shape: \t (768,)\n",
      "4\n",
      "Layer name: \t tf_bert_model/bert/embeddings/LayerNorm/beta:0\n",
      "Layer shape: \t (768,)\n",
      "5\n",
      "Layer name: \t tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0\n",
      "Layer shape: \t (768, 768)\n",
      "6\n",
      "Layer name: \t tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0\n",
      "Layer shape: \t (768,)\n",
      "7\n",
      "Layer name: \t tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0\n",
      "Layer shape: \t (768, 768)\n",
      "8\n",
      "Layer name: \t tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0\n",
      "Layer shape: \t (768,)\n",
      "9\n",
      "Layer name: \t tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0\n",
      "Layer shape: \t (768, 768)\n",
      "10\n",
      "Layer name: \t tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0\n",
      "Layer shape: \t (768,)\n"
     ]
    }
   ],
   "source": [
    "for layer in range(11):\n",
    "    print(layer)\n",
    "    print('Layer name: \\t', bert.layers[0].weights[layer].name)\n",
    "    print('Layer shape: \\t', bert.layers[0].weights[layer].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's point out a few observations:\n",
    "\n",
    " * We see the embedding layer which maps the token id to a 768 dim vector \n",
    " * Next is the positional encoding which encodes the 512 BERT input positions. looks right.\n",
    " * Layers 5-10 hold the weights and biases for the first self-attention layer\n",
    " \n",
    "So this all seems consistent and as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the BERT model available, let us create a sample input and then look at the BERT output.\n",
    "\n",
    "BERT has various inputs, but most of them optional (see: https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel). The minimum input are the input ids that should be of shape 'batch size' x 'sequence length'. (Note that in the text further down we will actually construct other inputs as well to be maximally explicit).\n",
    "\n",
    "Here is the proper input of our sample sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    4,  1121,  1254,  1232, 30976, 25920,  2029, 30976,  1008,\n",
       "            1,     1,     1,     5]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = np.array([tokenizer.encode('I am very happy today. [PAD] [PAD] [PAD]')])\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([25920])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   4, 1435, 1355, 3416, 2066, 1008,    1,    1,    1,    5]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = np.array([tokenizer.encode('Estoy muy feliz hoy. [PAD] [PAD] [PAD]')])\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feliz']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([3416])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks right: batch size 1, and length is 13. Now let's look at the bert output for this input. We follow here the Functional API way of thinking as 'output = layer(input)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_output = bert(input_ids)\n",
    "len(bert_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 2 outputs. What are their shapes and interpretation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 10, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_output[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first output with dimension 'batch size' x 'length' x 768 are the 768 dimensional **context-based embeddings** of each input token! These are what will replace the traditional word embeddings.\n",
    "\n",
    "Let's look at the output vector for the word happy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([ 0.43095678, -0.47853106, -0.40964997,  0.35057393,  1.3223889 ,\n",
       "        0.7433176 ,  0.51553565, -0.831788  , -1.175854  ,  0.02941999,\n",
       "       -0.7563708 , -0.30717418, -0.9192962 , -0.55995166,  0.03887059,\n",
       "       -0.18420003, -0.8522604 ,  0.64662915,  0.24861006,  0.44361466],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_vec = bert_output[0][0, 4]\n",
    "happy_vec[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the second BERT output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_output[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second output is the 'pooler output', which is the output of the CLS token, followed by another linear classification with tanh activation.\n",
    "\n",
    "Now, where we understand the tokernizer and the 'black box basics' of BERT, we are ready to work on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.3. Input Generation<a id=\"extract\"/>\n",
    "\n",
    "\n",
    "We have seen above how the data set looks. We can now turn to the pre-processing and creating the input for BERT. Specifically, we need to:\n",
    "\n",
    "1) Tokenize the sentences. Note again that one word can be split into multiple tokens, and we need to insert custom labels when that happens to make sure we don't mess up the alignment. We choose a new 'nerX' label here.\n",
    "\n",
    "2) Create BERT tokens and add [CLS], [PAD], etc.\n",
    "\n",
    "3) Convert these tokens into ids, also via the tokenizer. These qill create the sentence_ids.\n",
    "\n",
    "4) Create the mask ids. Mask out all of the padding tokens.\n",
    "\n",
    "5) Create the sequence ids. In our case, they are all '0' as we do not compare or even have multiple sentences in one example.\n",
    "\n",
    "To do this, we first define a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWord(word, pos, ner):\n",
    "    \"\"\"\n",
    "    Convert a word into a word token and add supplied NER and POS labels. Note that the word can be  \n",
    "    tokenized to two or more tokens. Correspondingly, we add - for now - custom 'X' tokens to the labels in order to \n",
    "    maintain the 1:1 mappings between word tokens and labels.\n",
    "    \n",
    "    arguments: word, pos label, ner label\n",
    "    returns: dictionary with tokens and labels\n",
    "    \"\"\"\n",
    "    # the dataset contains various '\"\"\"' combinations which we choose to truncate to '\"', etc. \n",
    "    if word == '\"\"\"\"':\n",
    "        word = '\"'\n",
    "    elif word == '``':\n",
    "        word = '`'\n",
    "        \n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n",
    "    \n",
    "    addDict = dict()\n",
    "    \n",
    "    addDict['wordToken'] = tokens\n",
    "    addDict['posToken'] = [pos] + ['posX'] * (tokenLength - 1)\n",
    "    addDict['nerToken'] = [ner] + ['nerX'] * (tokenLength - 1)\n",
    "    addDict['tokenLength'] = tokenLength\n",
    "    \n",
    "    \n",
    "    return addDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['protes', '##t'],\n",
       " 'posToken': ['VB', 'posX'],\n",
       " 'nerToken': ['O', 'nerX'],\n",
       " 'tokenLength': 2}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('protest', 'VB', 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['iraq'],\n",
       " 'posToken': ['NNP'],\n",
       " 'nerToken': ['B-geo'],\n",
       " 'tokenLength': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('Iraq', 'NNP', 'B-geo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['1000', '##0'],\n",
       " 'posToken': ['CD', 'posX'],\n",
       " 'nerToken': ['O', 'nerX'],\n",
       " 'tokenLength': 2}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('10000', 'CD', 'O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to convert the text file into appropriate arrays. First, we need to define the length of each example. For this we will define the hyper-parameter max_length. All sentences longer (post-tokenization!) than this parameter will be clipped off, and all sentences that are shorter will be padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read the file line by line and construct sentences. A sentence end is marked by the word 'sentence' in the next row.\n",
    "You need to take care of that. Also, you need to cap sentence length using max_length. Sentences which are shorter than \n",
    "max_length need to be padded. Also, we choose to end all sentences with a [SEP] token, padded or not. \n",
    "\"\"\"\n",
    "train_file, eval_file, test_file = train_args.train_dev_data\n",
    "\n",
    "with io.open(f'{train_file}', 'r', encoding='utf-8', errors='ignore') as train:\n",
    "    text = train.readlines()\n",
    "\n",
    "with io.open(f'{eval_file}', 'r', encoding='utf-8', errors='ignore') as eval:\n",
    "    text.extend(eval.readlines())\n",
    "\n",
    "# with io.open(f'{test_file}', 'r', encoding='utf-8', errors='ignore') as eval:\n",
    "#     text.extend(eval.readlines())\n",
    "    \n",
    "\n",
    "# lists for sentences, tokens, labels, etc.  \n",
    "sentenceList = []\n",
    "sentenceTokenList = []\n",
    "posTokenList = []\n",
    "nerTokenList = []\n",
    "sentLengthList = []\n",
    "\n",
    "# lists for BERT input\n",
    "bertSentenceIDs = []\n",
    "bertMasks = []\n",
    "bertSequenceIDs = []\n",
    "\n",
    "sentence = ''\n",
    "\n",
    "# always start with [CLS] tokens\n",
    "sentenceTokens = ['[CLS]']\n",
    "posTokens = ['[posCLS]']\n",
    "nerTokens = ['[nerCLS]']\n",
    "\n",
    "for line in text:\n",
    "    cleanLine = re.sub(r'(?!(([^\"]*\"){2})*[^\"]*$),', '', line)  # deal with '\"10,000\"' and convert them to '10000' \n",
    "\n",
    "    sent, word, pos, ner = cleanLine.split(',')\n",
    "    \n",
    "    ner = ner[:-1]   # remove DOS token\n",
    "    \n",
    "    # if new sentence starts\n",
    "    if (sent[:8] == 'Sentence'):            \n",
    "            \n",
    "        sentenceLength = min(max_length -1, len(sentenceTokens))\n",
    "        sentLengthList.append(sentenceLength)\n",
    "        \n",
    "                    \n",
    "        # Create space for at least a final '[SEP]' token\n",
    "        if sentenceLength >= max_length - 1: \n",
    "            sentenceTokens = sentenceTokens[:max_length - 2]\n",
    "            posTokens = posTokens[:max_length - 2]\n",
    "            nerTokens = nerTokens[:max_length - 2]\n",
    "\n",
    "        # add a ['SEP'] token and padding\n",
    "        \n",
    "        sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
    "        \n",
    "        posTokens += ['[posSEP]'] + ['[posPAD]'] * (max_length - 1 - len(posTokens) )\n",
    "        nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n",
    "            \n",
    "        sentenceList.append(sentence)\n",
    "\n",
    "        sentenceTokenList.append(sentenceTokens)\n",
    "\n",
    "        bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
    "        bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n",
    "        bertSequenceIDs.append([0] * (max_length))\n",
    "                             \n",
    "        posTokenList.append(posTokens)\n",
    "        nerTokenList.append(nerTokens)\n",
    "        \n",
    "        sentence = ''\n",
    "        sentenceTokens = ['[CLS]']\n",
    "        posTokens = ['[posCLS]']\n",
    "        nerTokens = ['[nerCLS]']\n",
    "        \n",
    "        sentence += ' ' + word\n",
    "\n",
    "    addDict = addWord(word, pos, ner)\n",
    "\n",
    "    sentenceTokens += addDict['wordToken']\n",
    "    posTokens += addDict['posToken']\n",
    "    nerTokens += addDict['nerToken']\n",
    "\n",
    "# The first two list elements need to be removed. 1st line in file is a-typical, and 2nd line does not end a sentence   \n",
    "sentLengthList = sentLengthList[2:]\n",
    "sentenceTokenList = sentenceTokenList[2:]\n",
    "bertSentenceIDs = bertSentenceIDs[2:]\n",
    "bertMasks = bertMasks[2:]\n",
    "bertSequenceIDs = bertSequenceIDs[2:]\n",
    "posTokenList = posTokenList[2:]\n",
    "nerTokenList = nerTokenList[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'yo', 'ir', '##ia', 'ha', '##w', '##aii', 'porque', 'la', 'clima', 'caliente', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[nerCLS]', 'O', 'O', 'nerX', 'O', 'nerX', 'nerX', 'O', 'B-ga', 'O', 'O', 'O', '[nerSEP]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]']\n"
     ]
    }
   ],
   "source": [
    "print(nerTokenList[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertMasks[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks right. Everything past the '[SEP]' token, i.e., the '[nerSEP]' label, is masked out. Also the sequence_ids are correct: there is only one sentence, so all ids should have the same value of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertSequenceIDs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable. \n",
    "\n",
    "\n",
    "### III.3. Initial Data Analysis<a id=\"analysis\" />\n",
    "\n",
    "It is important to understand the dataset prior to doing any modeling or training. First, what are the length of the original sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   4.,  20.,  49., 118., 155., 165., 185., 251., 218., 221.,\n",
       "        262., 232.,   0., 223., 201., 183., 161., 148., 141., 123.,  87.,\n",
       "         77., 106.,  79.,  47.,  67., 482.]),\n",
       " array([ 3.        ,  3.92857143,  4.85714286,  5.78571429,  6.71428571,\n",
       "         7.64285714,  8.57142857,  9.5       , 10.42857143, 11.35714286,\n",
       "        12.28571429, 13.21428571, 14.14285714, 15.07142857, 16.        ,\n",
       "        16.92857143, 17.85714286, 18.78571429, 19.71428571, 20.64285714,\n",
       "        21.57142857, 22.5       , 23.42857143, 24.35714286, 25.28571429,\n",
       "        26.21428571, 27.14285714, 28.07142857, 29.        ]),\n",
       " <BarContainer object of 28 artists>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentenceLengths= [l for l in sentLengthList]\n",
    "\n",
    "plt.hist(np.array(sentenceLengths), bins=(max_length-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An average sentence length of ~25 (incl. extra tokens!) is roughly expected. It turns out that on these types of corpora an average sentence length of ~20 tends to be seen. The big spike on the right obviously corresponds to all sentences that we had to truncate. \n",
    "\n",
    "Next, we analyze the distribution of ner labels. First, we assign numbers to the labels and look at the overall distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bertSentenceIDs)\n",
    "\n",
    "nerClasses = pd.DataFrame(np.array(nerTokenList).reshape(-1))\n",
    "nerClasses.columns = ['tag']\n",
    "nerClasses.tag = pd.Categorical(nerClasses.tag)\n",
    "nerClasses['cat'] = nerClasses.tag.cat.codes\n",
    "nerClasses['sym'] = nerClasses.tag.cat.codes\n",
    "nerLabels = np.array(nerClasses.cat).reshape(numSentences, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot: title={'center': 'cat'}>]], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nerClasses[['cat']].hist(bins=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a lot of tables with value 2+... Let's see which labels these label numbers corresponds to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | tag      |   cat |   occurences |\n",
      "|---:|:---------|------:|-------------:|\n",
      "|  0 | B-ga     |     0 |         2610 |\n",
      "|  1 | B-ga     |     1 |            0 |\n",
      "|  2 | B-ga     |     2 |            0 |\n",
      "|  3 | B-ga     |     3 |            0 |\n",
      "|  4 | B-ga     |     4 |            0 |\n",
      "|  5 | B-ga     |     5 |            0 |\n",
      "|  6 | B-ga     |     6 |            0 |\n",
      "|  7 | B-na     |     0 |            0 |\n",
      "|  8 | B-na     |     1 |         1289 |\n",
      "|  9 | B-na     |     2 |            0 |\n",
      "| 10 | B-na     |     3 |            0 |\n",
      "| 11 | B-na     |     4 |            0 |\n",
      "| 12 | B-na     |     5 |            0 |\n",
      "| 13 | B-na     |     6 |            0 |\n",
      "| 14 | O        |     0 |            0 |\n",
      "| 15 | O        |     1 |            0 |\n",
      "| 16 | O        |     2 |        52599 |\n",
      "| 17 | O        |     3 |            0 |\n",
      "| 18 | O        |     4 |            0 |\n",
      "| 19 | O        |     5 |            0 |\n",
      "| 20 | O        |     6 |            0 |\n",
      "| 21 | [nerCLS] |     0 |            0 |\n",
      "| 22 | [nerCLS] |     1 |            0 |\n",
      "| 23 | [nerCLS] |     2 |            0 |\n",
      "| 24 | [nerCLS] |     3 |         4006 |\n",
      "| 25 | [nerCLS] |     4 |            0 |\n",
      "| 26 | [nerCLS] |     5 |            0 |\n",
      "| 27 | [nerCLS] |     6 |            0 |\n",
      "| 28 | [nerPAD] |     0 |            0 |\n",
      "| 29 | [nerPAD] |     1 |            0 |\n",
      "| 30 | [nerPAD] |     2 |            0 |\n",
      "| 31 | [nerPAD] |     3 |            0 |\n",
      "| 32 | [nerPAD] |     4 |        47803 |\n",
      "| 33 | [nerPAD] |     5 |            0 |\n",
      "| 34 | [nerPAD] |     6 |            0 |\n",
      "| 35 | [nerSEP] |     0 |            0 |\n",
      "| 36 | [nerSEP] |     1 |            0 |\n",
      "| 37 | [nerSEP] |     2 |            0 |\n",
      "| 38 | [nerSEP] |     3 |            0 |\n",
      "| 39 | [nerSEP] |     4 |            0 |\n",
      "| 40 | [nerSEP] |     5 |         4006 |\n",
      "| 41 | [nerSEP] |     6 |            0 |\n",
      "| 42 | nerX     |     0 |            0 |\n",
      "| 43 | nerX     |     1 |            0 |\n",
      "| 44 | nerX     |     2 |            0 |\n",
      "| 45 | nerX     |     3 |            0 |\n",
      "| 46 | nerX     |     4 |            0 |\n",
      "| 47 | nerX     |     5 |            0 |\n",
      "| 48 | nerX     |     6 |         7867 |\n"
     ]
    }
   ],
   "source": [
    "nerDistribution = (nerClasses.groupby(['tag', 'cat']).agg({'sym':'count'}).reset_index()\n",
    "                   .rename(columns={'sym':'occurences'}))\n",
    "\n",
    "numNerClasses = nerDistribution.tag.nunique()\n",
    "\n",
    "print(nerDistribution.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. 2 corresponds to 'O', and all 'extension' labels (i.e., those that were not part of the original data) occur at 2+. \n",
    "\n",
    "'O' is the most common token - by far.\n",
    "\n",
    "### III.4. Baseline: Always picking 'Other'<a id=\"baseline\" />\n",
    "\n",
    "Let's see what a baseline would give for the actual text tokens, if I ALWAYS chose the most common token 'O':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52599/56498 = 0.9309887075648695\n"
     ]
    }
   ],
   "source": [
    "O_occurences = int(nerDistribution.loc[nerDistribution.tag == 'O','occurences']\\\n",
    "                                .reset_index().drop(['index'], axis=1).loc[2])   # Some gymnasics to get the count..\n",
    "All_occurences = nerDistribution[nerDistribution.cat < 3]['occurences'].sum()\n",
    "\n",
    "print(f'{O_occurences}/{All_occurences} = {O_occurences/All_occurences}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So **93.1%** is the baseline to beat for our first metric! Can we do that? We'll see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.5. Train/Test Split and Final Data Preparation<a id=\"split\" />\n",
    "\n",
    "In the last step we need to prepare both labels and input for the model, including the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split - in a pretty manual way - the examples into a train and test set. We create a random binary value for each sentence that we use to split train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bert_inputs[0])\n",
    "np.random.seed(0)\n",
    "training_examples = np.random.binomial(1, 0.7, numSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSentence_ids = []\n",
    "trainMasks = []\n",
    "trainSequence_ids = []\n",
    "\n",
    "testSentence_ids = []\n",
    "testMasks = []\n",
    "testSequence_ids = []\n",
    "\n",
    "nerLabels_train =[]\n",
    "nerLabels_test = []\n",
    "\n",
    "\n",
    "for example in range(numSentences):\n",
    "    if training_examples[example] == 1:\n",
    "        trainSentence_ids.append(bert_inputs[0][example])\n",
    "        trainMasks.append(bert_inputs[1][example])\n",
    "        trainSequence_ids.append(bert_inputs[2][example])\n",
    "        nerLabels_train.append(nerLabels[example])\n",
    "    else:\n",
    "        testSentence_ids.append(bert_inputs[0][example])\n",
    "        testMasks.append(bert_inputs[1][example])\n",
    "        testSequence_ids.append(bert_inputs[2][example])\n",
    "        nerLabels_test.append(nerLabels[example])\n",
    "        \n",
    "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
    "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
    "\n",
    "nerLabels_train = np.array(nerLabels_train)\n",
    "nerLabels_test = np.array(nerLabels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    4,  1035,  1136,  6562, 27405,  1100,  1100,  1252, 28047,\n",
       "        1035,  9366,  3861,  1008,     5,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 2, 2, 2, 6, 2, 2, 2, 2, 6, 2, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4], dtype=int8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerLabels_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'en', 'mi', 'vacaciones', 'perfectas', '\"', '\"', 'yo', 'empezaré', 'en', 'eng', '##land', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also get a few train/test positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_examples[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step, we prepare the actual train and test input and label data. For convenience (quick functionality test on small data set), we introduce parameters k_start & k_end to just use a slide of the full dataset. (Setting k_end to -1 corresponds to using the whole set (as we will do in the following). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n",
    "\n",
    "k_start = 0\n",
    "k_end = -1\n",
    "\n",
    "if k_end == -1:\n",
    "    k_end_train = X_train[0].shape[0]\n",
    "    k_end_test = X_test[0].shape[0]\n",
    "else:\n",
    "    k_end_train = k_end_test = k_end\n",
    "    \n",
    "\n",
    "\n",
    "bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n",
    "                       X_train[2][k_start:k_end_train]]\n",
    "bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n",
    "                      X_test[2][k_start:k_end_test]]\n",
    "\n",
    "\n",
    "labels_train_k = nerLabels_train[k_start:k_end_train]\n",
    "labels_test_k = nerLabels_test[k_start:k_end_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = [bert_inputs_train_k, labels_train_k]\n",
    "test_all = [bert_inputs_test_k, labels_test_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"./plain_train_data.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(train_all, output_file)\n",
    "    \n",
    "with open(r\"./plain_test_data.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(test_all, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"./plain_train_data.pickle\", \"rb\") as input_file:\n",
    "    bert_inputs_train_k, labels_train_k = train_all = pickle.load(input_file)\n",
    "    \n",
    "with open(r\"./plain_test_data.pickle\", \"rb\") as input_file:\n",
    "    bert_inputs_test_k, labels_test_k = test_all = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "numNerClasses = 7  # for fast restart w/o the need to recreate data\n",
    "\n",
    "#X_train = np.array(train_all[0])\n",
    "#Y_train = np.array(train_all[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. We are all set to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. The Model<a id=\"model\"/>\n",
    "\n",
    "### IV.1. Custom Loss & Accuracy<a id=\"custom\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a **custom loss function** because we only want to optimize for the labels that we actually had in the text, not the extra ones like '[nerPAD]', etc. Our cost function is therefore derived from sparse_categorical_crossentropy, but we choose to modify the function a bit:  we want to mask out all tokens that have a token id larger or equal of 17, corresponding to the extra tokens:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss function explicitly, filtering out 'extra inserted labels'\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length + 1) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns:  cost\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(Flatten()(tf.cast(y_true, tf.int32)),[-1])\n",
    "    \n",
    "    mask = (y_label < 3)   # This mask is used to remove all tokens that do not correspond to the original base text.\n",
    "\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n",
    "    \n",
    "    y_flat_pred = tf.reshape(Flatten()(tf.cast(y_pred, tf.float32)),[-1, numNerClasses])\n",
    "    \n",
    "    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n",
    "    \n",
    "    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=False ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it work as advertised? Let's create a toy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (6,) and (2,) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [56], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([\n\u001b[1;32m      4\u001b[0m     [\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0.6\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m.4\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      5\u001b[0m     [\u001b[38;5;241m0.6\u001b[39m,\u001b[38;5;241m0.4\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      6\u001b[0m ])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Nice to have eager execution now...\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcustom_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn [54], line 21\u001b[0m, in \u001b[0;36mcustom_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     17\u001b[0m y_label_masked \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mboolean_mask(y_label, mask)  \u001b[38;5;66;03m# mask the labels\u001b[39;00m\n\u001b[1;32m     19\u001b[0m y_flat_pred \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(Flatten()(tf\u001b[38;5;241m.\u001b[39mcast(y_pred, tf\u001b[38;5;241m.\u001b[39mfloat32)),[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, numNerClasses])\n\u001b[0;32m---> 21\u001b[0m y_flat_pred_masked \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboolean_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_flat_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# mask the predictions\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m ))\n",
      "File \u001b[0;32m~/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/tensorflow/python/framework/tensor_shape.py:1307\u001b[0m, in \u001b[0;36mTensorShape.assert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;124;03m\"\"\"Raises exception if `self` and `other` do not represent the same shape.\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \n\u001b[1;32m   1297\u001b[0m \u001b[38;5;124;03mThis method can be used to assert that there exists a shape that both\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;124;03m  ValueError: If `self` and `other` do not represent the same shape.\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_compatible_with(other):\n\u001b[0;32m-> 1307\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapes \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m are incompatible\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m, other))\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (6,) and (2,) are incompatible"
     ]
    }
   ],
   "source": [
    "y_true = tf.constant([[3],[0]])\n",
    "\n",
    "y_pred = tf.constant([\n",
    "    [0.0,0,0,0.6,0,0,0,0,0,0,0,0,0,0,0,0,0,.4,0,0,0],\n",
    "    [0.6,0.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "])\n",
    "\n",
    "\n",
    "# Nice to have eager execution now...\n",
    "\n",
    "print(custom_loss(y_true, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the manual calculation of $-\\log((y^1_{pred})_0)$ (remember that $y^0$ is masked out because the true label is 17) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5108256237659907"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is correct! The position where the true label is 17 is ignored because of the mask!\n",
    "\n",
    "In a similar vein, we define and test a **custom accuracy** calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc_orig_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss dfunction filtering out also the newly inserted labels\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns: accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask = (y_label < 3)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also define another accuracy calculation that only looks at the non-Other labels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc_orig_non_other_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss dfunction explicitly filtering out also the 'Other'- labels\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns: accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask = (y_label < 2)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (6,) and (2,) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [60], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m y_true \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m17\u001b[39m],[\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([\n\u001b[1;32m      4\u001b[0m     [\u001b[38;5;241m0.6\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m.4\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      5\u001b[0m     [\u001b[38;5;241m0.6\u001b[39m,\u001b[38;5;241m0.4\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      6\u001b[0m ])\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcustom_acc_orig_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn [58], line 21\u001b[0m, in \u001b[0;36mcustom_acc_orig_tokens\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     16\u001b[0m y_label_masked \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mboolean_mask(y_label, mask)\n\u001b[1;32m     18\u001b[0m y_predicted \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten()(tf\u001b[38;5;241m.\u001b[39mcast(y_pred, tf\u001b[38;5;241m.\u001b[39mfloat64)),\\\n\u001b[1;32m     19\u001b[0m                                                 [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, numNerClasses]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m y_predicted_masked \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboolean_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_predicted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39mcast(tf\u001b[38;5;241m.\u001b[39mequal(y_predicted_masked,y_label_masked) , dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat64))\n",
      "File \u001b[0;32m~/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/tensorflow/python/framework/tensor_shape.py:1307\u001b[0m, in \u001b[0;36mTensorShape.assert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;124;03m\"\"\"Raises exception if `self` and `other` do not represent the same shape.\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \n\u001b[1;32m   1297\u001b[0m \u001b[38;5;124;03mThis method can be used to assert that there exists a shape that both\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;124;03m  ValueError: If `self` and `other` do not represent the same shape.\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_compatible_with(other):\n\u001b[0;32m-> 1307\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapes \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m are incompatible\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m, other))\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (6,) and (2,) are incompatible"
     ]
    }
   ],
   "source": [
    "y_true = tf.constant([[17],[0]])\n",
    "\n",
    "y_pred = tf.constant([\n",
    "    [0.6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,.4,0,0,0],\n",
    "    [0.6,0.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "])\n",
    "\n",
    "\n",
    "print(custom_acc_orig_tokens(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again... correct! The false value for the '17' example is not considered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, define an Adam optimizer with new learning rate and beta parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "adam_customized = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.91, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the summary statistics for TensorBoard. And then we can construct the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.2 Model Construction<a id=\"ner_model\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to build the model! Let's be pretty simple. No drop-out etc for now. But we re-train three BERT layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_model(max_input_length, train_layers, optimizer):\n",
    "    \"\"\"\n",
    "    Implementation of NER model\n",
    "    \n",
    "    variables:\n",
    "        max_input_length: number of tokens (max_length + 1)\n",
    "        train_layers: number of layers to be retrained\n",
    "        optimizer: optimizer to be used\n",
    "    \n",
    "    returns: model\n",
    "    \"\"\"\n",
    "    \n",
    "    in_id = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"segment_ids\")\n",
    "    \n",
    "    \n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Note: Bert layer from Hugging Face returns two values: sequence ouput, and pooled output. Here, we only want\n",
    "    # the former. (See https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel) \n",
    "    \n",
    "    bert_layer = TFBertModel.from_pretrained('bert-base-cased')\n",
    "    \n",
    "    # Freeze layers, i.e. only train number of layers specified, starting from the top\n",
    "    \n",
    "    if not train_layers == -1:\n",
    "        \n",
    "        retrain_layers = []\n",
    "    \n",
    "        for retrain_layer_number in range(train_layers):\n",
    "\n",
    "            layer_code = '_' + str(11 - retrain_layer_number)\n",
    "            retrain_layers.append(layer_code)\n",
    "\n",
    "        for w in bert_layer.weights:\n",
    "            if not any([x in w.name for x in retrain_layers]):\n",
    "                w._trainable = False\n",
    "\n",
    "        # End of freezing section\n",
    "    \n",
    "    bert_sequence = bert_layer(bert_inputs)[0]\n",
    "    \n",
    "    print('Let us check the shape of the BERT layer output:', bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
    "    \n",
    "    pred = tf.keras.layers.Dense(7, activation='softmax', name='ner')(dense)\n",
    "     \n",
    "    print('pred: ', pred)\n",
    "    \n",
    "    ## Prepare for multipe loss functions, although not used here\n",
    "    \n",
    "    losses = {\n",
    "        \"ner\": custom_loss,\n",
    "        }\n",
    "    lossWeights = {\"ner\": 1.0\n",
    "                  }\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "\n",
    "    model.compile(loss=losses, optimizer=optimizer, metrics=[custom_acc_orig_tokens, \n",
    "                                                          custom_acc_orig_non_other_tokens])\n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## V. Model Runs/Experiments<a id=\"runs\"/>\n",
    "\n",
    "### V.1. With BERT-Layer Re-Training<a id=\"retrain\"/>\n",
    "\n",
    "It is time to run the first test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    4,  1035,  1136,  6562, 27405,  1100,  1100,  1252, 28047,\n",
       "        1035,  9366,  3861,  1008,     5,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_inputs_train_k[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us choose to retrain the all layers of BERT and then train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 30, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n",
      "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 30, 7), dtype=tf.float32, name=None), name='ner/Softmax:0', description=\"created by layer 'ner'\")\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " input_masks (InputLayer)       [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'input_masks[0][0]',            \n",
      "                                tentions(last_hidde               'segment_ids[0][0]']            \n",
      "                                n_state=(None, 30,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 30, 256)      196864      ['tf_bert_model[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 30, 256)      0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " ner (Dense)                    (None, 30, 7)        1799        ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,508,935\n",
      "Trainable params: 108,508,935\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 21:35:06.902897: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-11-20 21:35:11.295948: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/tf_bert_model/bert/embeddings/assert_less/Assert/Assert' defined at (most recent call last):\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n      app.start()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/g2/7p9zflv569l_wm_5vy9zvdbr0000gn/T/ipykernel_56940/2510944333.py\", line 6, in <module>\n      model.fit(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1061, in run_call_with_unpacked_inputs\n      [`TFPreTrainedModel`] takes care of storing the configuration of the models and handles methods for loading,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1088, in call\n      outputs = self.bert(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1061, in run_call_with_unpacked_inputs\n      [`TFPreTrainedModel`] takes care of storing the configuration of the models and handles methods for loading,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 780, in call\n      embedding_output = self.embeddings(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 201, in call\n      if input_ids is not None:\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 202, in call\n      check_embeddings_within_bounds(input_ids, self.config.vocab_size)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/tf_utils.py\", line 161, in check_embeddings_within_bounds\n      tf.debugging.assert_less(\nNode: 'model/tf_bert_model/bert/embeddings/assert_less/Assert/Assert'\nDetected at node 'model/tf_bert_model/bert/embeddings/assert_less/Assert/Assert' defined at (most recent call last):\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n      app.start()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/g2/7p9zflv569l_wm_5vy9zvdbr0000gn/T/ipykernel_56940/2510944333.py\", line 6, in <module>\n      model.fit(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1061, in run_call_with_unpacked_inputs\n      [`TFPreTrainedModel`] takes care of storing the configuration of the models and handles methods for loading,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1088, in call\n      outputs = self.bert(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1061, in run_call_with_unpacked_inputs\n      [`TFPreTrainedModel`] takes care of storing the configuration of the models and handles methods for loading,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 780, in call\n      embedding_output = self.embeddings(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 201, in call\n      if input_ids is not None:\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 202, in call\n      check_embeddings_within_bounds(input_ids, self.config.vocab_size)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/tf_utils.py\", line 161, in check_embeddings_within_bounds\n      tf.debugging.assert_less(\nNode: 'model/tf_bert_model/bert/embeddings/assert_less/Assert/Assert'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  assertion failed: [The maximum value of input_ids (Tensor(\\\"model/tf_bert_model/bert/embeddings/Max:0\\\", shape=(), dtype=int32)) must be smaller than the embedding layer\\'s input dimension (28996). The likely cause is some problem at tokenization time.] [Condition x < y did not hold element-wise:] [x (model/Cast:0) = ] [[4 1388 1100...]...] [y (model/tf_bert_model/bert/embeddings/Cast/x:0) = ] [28996]\n\t [[{{node model/tf_bert_model/bert/embeddings/assert_less/Assert/Assert}}]]\n\t [[boolean_mask_1/Squeeze/_54]]\n  (1) INVALID_ARGUMENT:  assertion failed: [The maximum value of input_ids (Tensor(\\\"model/tf_bert_model/bert/embeddings/Max:0\\\", shape=(), dtype=int32)) must be smaller than the embedding layer\\'s input dimension (28996). The likely cause is some problem at tokenization time.] [Condition x < y did not hold element-wise:] [x (model/Cast:0) = ] [[4 1388 1100...]...] [y (model/tf_bert_model/bert/embeddings/Cast/x:0) = ] [28996]\n\t [[{{node model/tf_bert_model/bert/embeddings/assert_less/Assert/Assert}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_32650]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [65], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# retrain all layers\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m ner_model(max_length \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, train_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, optimizer \u001b[38;5;241m=\u001b[39m adam_customized)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbert_inputs_train_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mner\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_train_k\u001b[49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbert_inputs_test_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mner\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_test_k\u001b[49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model/tf_bert_model/bert/embeddings/assert_less/Assert/Assert' defined at (most recent call last):\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n      app.start()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/g2/7p9zflv569l_wm_5vy9zvdbr0000gn/T/ipykernel_56940/2510944333.py\", line 6, in <module>\n      model.fit(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1061, in run_call_with_unpacked_inputs\n      [`TFPreTrainedModel`] takes care of storing the configuration of the models and handles methods for loading,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1088, in call\n      outputs = self.bert(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1061, in run_call_with_unpacked_inputs\n      [`TFPreTrainedModel`] takes care of storing the configuration of the models and handles methods for loading,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 780, in call\n      embedding_output = self.embeddings(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 201, in call\n      if input_ids is not None:\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 202, in call\n      check_embeddings_within_bounds(input_ids, self.config.vocab_size)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/tf_utils.py\", line 161, in check_embeddings_within_bounds\n      tf.debugging.assert_less(\nNode: 'model/tf_bert_model/bert/embeddings/assert_less/Assert/Assert'\nDetected at node 'model/tf_bert_model/bert/embeddings/assert_less/Assert/Assert' defined at (most recent call last):\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n      app.start()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/g2/7p9zflv569l_wm_5vy9zvdbr0000gn/T/ipykernel_56940/2510944333.py\", line 6, in <module>\n      model.fit(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1061, in run_call_with_unpacked_inputs\n      [`TFPreTrainedModel`] takes care of storing the configuration of the models and handles methods for loading,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1088, in call\n      outputs = self.bert(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1061, in run_call_with_unpacked_inputs\n      [`TFPreTrainedModel`] takes care of storing the configuration of the models and handles methods for loading,\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 780, in call\n      embedding_output = self.embeddings(\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 201, in call\n      if input_ids is not None:\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 202, in call\n      check_embeddings_within_bounds(input_ids, self.config.vocab_size)\n    File \"/Users/rams/miniforge3/envs/env_arm_py39/lib/python3.9/site-packages/transformers/tf_utils.py\", line 161, in check_embeddings_within_bounds\n      tf.debugging.assert_less(\nNode: 'model/tf_bert_model/bert/embeddings/assert_less/Assert/Assert'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  assertion failed: [The maximum value of input_ids (Tensor(\\\"model/tf_bert_model/bert/embeddings/Max:0\\\", shape=(), dtype=int32)) must be smaller than the embedding layer\\'s input dimension (28996). The likely cause is some problem at tokenization time.] [Condition x < y did not hold element-wise:] [x (model/Cast:0) = ] [[4 1388 1100...]...] [y (model/tf_bert_model/bert/embeddings/Cast/x:0) = ] [28996]\n\t [[{{node model/tf_bert_model/bert/embeddings/assert_less/Assert/Assert}}]]\n\t [[boolean_mask_1/Squeeze/_54]]\n  (1) INVALID_ARGUMENT:  assertion failed: [The maximum value of input_ids (Tensor(\\\"model/tf_bert_model/bert/embeddings/Max:0\\\", shape=(), dtype=int32)) must be smaller than the embedding layer\\'s input dimension (28996). The likely cause is some problem at tokenization time.] [Condition x < y did not hold element-wise:] [x (model/Cast:0) = ] [[4 1388 1100...]...] [y (model/tf_bert_model/bert/embeddings/Cast/x:0) = ] [28996]\n\t [[{{node model/tf_bert_model/bert/embeddings/assert_less/Assert/Assert}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_32650]"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# retrain all layers\n",
    "model = ner_model(max_length + 1, train_layers=-1, optimizer = adam_customized)\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_k, \n",
    "    {\"ner\": labels_train_k },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k }),\n",
    "    epochs=5,\n",
    "    batch_size=16\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**97.0% test accuracy for all original tokens and 84.3% for all original 'non-Other' tokens.... Not bad!!** And some tweaking and tuning should probably increase the values a bit more.\n",
    "\n",
    "Note that we used here the **Adam optimizer with custom values. Did that matter?** Why don't you try it...\n",
    "\n",
    "### V.2. Predictions & Confusion Matrix<a id=\"confusion\" />\n",
    "\n",
    "\n",
    "Let us look and see how well the model performs. We use the test here. (It probably would be better to split the data into train/validation/test, we are somewhat casual here).\n",
    "\n",
    "First, get all of the predictions for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs_infer = [X_test[0], X_test[1], X_test[2]]\n",
    "\n",
    "result = model.predict(\n",
    "    bert_inputs_infer, \n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the correct shape: # test sentences x sentence length x # classes. \n",
    "Let's get the prediction argmax for a random test sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(result, axis=2)[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What were the labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nerLabels_test[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wrong? Correct!** Or.. is it?  \n",
    "\n",
    "**Question: Why are we not bothered by the first and the last 'mistakes', i.e., not identifying 20, 17, 19, 18, etc.?**\n",
    "\n",
    "Let us now get the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_flat = [pred for preds in np.argmax(result, axis=2) for pred in preds]\n",
    "labels_flat = [label for labels in nerLabels_test for label in labels]\n",
    "\n",
    "clean_preds = []\n",
    "clean_labels = []\n",
    "\n",
    "for pred, label in zip(predictions_flat, labels_flat):\n",
    "    if label < 17:\n",
    "        clean_preds.append(pred)\n",
    "        clean_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(\n",
    "    clean_labels,\n",
    "    clean_preds,\n",
    "    num_classes=None,\n",
    "    dtype=tf.dtypes.int32,\n",
    "    name=None,\n",
    "    weights=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably a little big and unbalanced to display. Let us focus on the rows/columns with the common labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(cm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_most = np.array(cm)[[2,3,5,6,7,13,14,16],:] [:, [2,3,5,6,7,13,14,16]]\n",
    "\n",
    "print(cm_most)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cm_most[:-1,:-1], cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.3 Without BERT-Layer Retraining (\"Did fine-tuning of BERT layers help?\")\n",
    "\n",
    "We will re-run the model, but without re-training of the top BERT layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ner_model(max_length + 1,train_layers=0,optimizer='adam')\n",
    "\n",
    "# Instantiate variables\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_k, \n",
    "    {\"ner\": labels_train_k },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n",
    "    epochs=8,\n",
    "    batch_size=32\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Somewhat close, but not quite as good.** - While one has to be careful given the different optimizer configurations and number of epochs, it looks as if not re-training BERT - in this case - increased the loss and reduced the accuracy a bit. Let's call this **~96.6%/81.6% accuracy** compared to 97.0%/84.3%. \n",
    "\n",
    "The relative benefit of fine-tuning BERT layers will depend on the problem.\n",
    "\n",
    "**Side Notes:** \n",
    " * Deeper re-training needs more compute resources\n",
    " * Deeper re-training sometimes requires a tuned optimizer\n",
    " * Regularization is definitely important..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.4. A 90%-Reduced Training Set<a id=\"tiny\"/>\n",
    "\n",
    "\n",
    "The claim is that BERT is also very useful if one doesn't have much data. So let us see what happens if we cut the training data down to 10%. That leaves us with only ~3400 training examples. Not much..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTrainSentences = 3370\n",
    "\n",
    "bert_inputs_train_tiny = [bert_inputs_train_k[0][:numTrainSentences,:], \\\n",
    "                          bert_inputs_train_k[1][:numTrainSentences,:], \\\n",
    "                          bert_inputs_train_k[2][:numTrainSentences,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_tiny = labels_train_k[:numTrainSentences,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first train without BERT-layer fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# retrain all layers\n",
    "model = ner_model(max_length + 1,train_layers=0,optimizer='adam')\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_tiny, \n",
    "    {\"ner\": labels_train_tiny },\n",
    "    epochs=5,\n",
    "    batch_size=16\n",
    ")\n",
    "model.fit(\n",
    "    bert_inputs_train_tiny, \n",
    "    {\"ner\": labels_train_tiny },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n",
    "    epochs=1,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad, one would think! **~95.3%/74.7%** on the test set, compared to ~96.6%/81.6% accuracy on the full training set (w/o BERT-layer re-training) with 1/10th of the data. So BERT embeddings are serving quite well for a smaller data set. \n",
    "\n",
    "At last, let us also compare this to the case where we retrain all BERT layers. This will shed light on the question whether retraining pays off relatively more when data is scarce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# retrain all layers\n",
    "model = ner_model(max_length + 1,train_layers=-1,optimizer=adam_customized)\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_tiny, \n",
    "    {\"ner\": labels_train_tiny },\n",
    "    epochs=5,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_tiny, \n",
    "    {\"ner\": labels_train_tiny },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n",
    "    epochs=1,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**96.2%/80.5%** on the reduced set, compared to 97.0%/84.3% test accuracy for all original tokens and for the full dataset (both with layer re-training). That is quite good - only a loss of about 0.8%-points/3.9%-points.\n",
    "\n",
    "Compare that also to the results without layer retraining: ~95.3%/74.7% for the 1/10 data set vs ~96.6%/81.6%  for the full training set, corresponding to a 1.3%-points/6.9%-point reduction.\n",
    "\n",
    "It appears that transfer-learning for small data sets may really benefit from layer re-training. Here is the summary table:\n",
    "\n",
    "\n",
    "|Dataset         | Retrain Layers?           | Base Token Accuracy   | Base Token Accuracy w/o 'Other'   | Notes  |\n",
    "| ------------- |:-------------:| :-------------:| :-------------:|-------------:|\n",
    "| **Full**       | Yes (all) | **97.0%** | **84.3%** |custom Adam, 5 epochs|\n",
    "| **Full**       | No      |   **96.6%** | **81.6%** |default Adam, 8 epochs|\n",
    "| **1/10**  |  Yes (all)      |   **96.2%** | **80.5%** |custom Adam, 6 epochs|\n",
    "| **1/10**  | No     |    **95.3%** | **74.7%**|default Adam, 6 epochs|\n",
    "\n",
    "\n",
    "**Disclaimers/Cautions:**\n",
    "\n",
    "* The models were generally not optimized and/or run for the optimal duration. Numbers of epochs are not consistent and were selected based on 'good-enough for now'-strategy.  Quite possibly some models would benefit from more epochs (and hyper-parameter tuning). \n",
    "\n",
    "* The optimizers (default 'Adam' vs the one with customized values) were varied across model runs, which has a significant impact and results are not directly comparable. (Note: it appears that for the reduced set, the model without layer re-training does not train well on the custom Adam-optimizer, while the one where we re-train all layers does not train with the default values.)\n",
    "\n",
    "Having said this, I do not believe that the findings above would be massively different with a more stringent setup. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Summary<a id=\"summary\" />\n",
    "\n",
    "This finishes this cursory analysis of \"BERT for NER\". We pre-formatted our dataset, took care of tokenization and new inserted tokens (and labels!), defined a baseline model, and then - it would have been embarassing if we had failed - soundly beat the baseline with our Keras-based BERT+classification model. We saw that retraining of some BERT layers appeared to work well.  \n",
    "We also saw that even a small training set of about 3400 sentences did quite well using this architecture.\n",
    "\n",
    "All in all, we hope that this notebook was useful and despite its length reasonably readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: T5<a id=\"T5\" />\n",
    "\n",
    "\n",
    "Let us now lay the foundations for another useful model: **T5**. \n",
    "\n",
    "T5 is a pre-trained transformer-based text-to-text model introduced by C. Raffel et al in  [\"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\"](https://arxiv.org/pdf/1910.10683.pdf) , that is also available from Huggingface.  The idea is to view/rephrase tasks as 'text-to-text' problems:   \n",
    "\n",
    "<img src=\"t5.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<center>Image Source: \"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\"</center>\n",
    "\n",
    "T5 has performed very well on a variety of tasks.\n",
    "\n",
    "In this spirit, let us approach the NER classification discussed above in a completely different may: **as a translation problem**. This may certainly lead to less good results than the BERT model, as phrasing it as a translation problem is not very natural. But it is instructive nevertheless.\n",
    "\n",
    "(**Note:** this is pretty cutting-edge as there is very little information available on fine-tuning of T5 with TensorFlow/Keras. So this notebook should be viewed as work in progress, and mistakes may be present.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5 is available in various sizes. Here, we use the small size with about 60m parameters.\n",
    "\n",
    "### T5 as a Black Box\n",
    "\n",
    "Let us first play with Huggingface's T5 model. We start with the T5ForConditionalGeneration model imported above to verify some pre-training claims. This model uses a source sentence AND the task as an input and then generates the output token by token.\n",
    "\n",
    "Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_model = 't5-small'\n",
    "\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(t5_model)\n",
    "t5 = TFT5ForConditionalGeneration.from_pretrained(t5_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the translation tasks. English to German works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokenizer('translate English to German: how large is the house?', return_tensors='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spanish is not part of the trained tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = t5_tokenizer('translate English to Spanish: the house is very large', return_tensors='tf').input_ids\n",
    "\n",
    "outputs = t5.generate(input_ids)\n",
    "\n",
    "t5_tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll check out the sentiment analysis task. 'sst2 sentence:' is the task instruction, which is then followed by the statement to classify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = t5_tokenizer('sst2 sentence: I am so happy today', return_tensors='tf').input_ids\n",
    "outputs = t5.generate(input_ids)\n",
    "t5_tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = t5_tokenizer('sst2 sentence: I am so sad today', return_tensors='tf').input_ids\n",
    "outputs = t5.generate(input_ids)\n",
    "t5_tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!\n",
    "\n",
    "Lastly, here is a summarization example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Hiring picked up last month as states lifted restrictions and stepped up vaccination efforts, \n",
    "with the government reporting on Friday that the American economy added 379,000 jobs last month.\n",
    "The pace of hiring in February was an unexpectedly large improvement over the gains made in January. \n",
    "It was also the strongest showing since October. But there are still about 9.5 million fewer jobs today \\\n",
    "than a year ago. Congress is considering a $1.9 trillion package of pandemic relief intended to carry \\\n",
    "struggling households and businesses through the coming months.\"\"\".replace('\\n', ' ')\n",
    "\n",
    "\n",
    "encoding = t5_tokenizer.encode(\"\"\"summarize: \"\"\" + text, return_tensors='tf')\n",
    "\n",
    "\n",
    "outputs = t5.generate(encoding,\n",
    "                      num_beams=4, \n",
    "                      no_repeat_ngram_size=2,\n",
    "                      min_length=30,\n",
    "                      max_length=100,\n",
    "                      early_stopping=True)\n",
    "\n",
    "summarization = t5_tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, that's a summary. It feels rather extractive. (The optional 'temperature' argument not used here would have an impact.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** \n",
    "\n",
    "* *Wait... why do we only give the encoder input? And how is this actually trained? What is the training input?*  \n",
    "\n",
    "We can address these later if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5 and our NER problem\n",
    "\n",
    "The basic idea is for us to rephrase NER extraction as a translation problem.\n",
    "\n",
    "So we want to frame a text-to-text task that performs the following 'translation':\n",
    "\n",
    "$$ {\\rm 'London \\ is \\ a \\ great \\ town'} \\ \\rightarrow  {\\rm 'B-loc \\ other \\ other \\ other \\ other'}$$ \n",
    "\n",
    "While it is unusual to view this as a translation problem, it is certainly valid.\n",
    "\n",
    "There are many ways to set up the data and labels. One way is to convert the NER symbols in ways that better map to language: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict = {'B-art':'begin cultural',\n",
    " 'B-eve':'begin event',\n",
    " 'B-geo':'begin location',\n",
    " 'B-gpe':'begin political',\n",
    " 'B-nat':'begin natural',\n",
    " 'B-org':'begin organization',\n",
    " 'B-per':'begin person',\n",
    " 'B-tim':'begin time',\n",
    " 'I-art':'continue cultural',\n",
    " 'I-eve':'continue event',\n",
    " 'I-geo':'continue location',\n",
    " 'I-gpe':'continue political',\n",
    " 'I-nat':'continue natural',\n",
    " 'I-org':'continue organization',\n",
    " 'I-per':'continue person',\n",
    " 'I-tim':'continue time',\n",
    " 'O':'other'}\n",
    "\n",
    "for key, tag in tag_dict.items():\n",
    "    print(key, t5_tokenizer.tokenize(tag), t5_tokenizer.encode(tag)[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify a maximum input length (we pick 40) and create the training input and labels.\n",
    "\n",
    "Note:\n",
    "\n",
    "* we prepend each sentence with a task description. We use: 'find entities:' . The padded, encoded version of this string consitutes the encoder input. (Note: encoding adds a padding token at the beginning and a <\\/s> token at the end, prior to the padding tokens.)\n",
    "\n",
    "* For the decoder input and the labels we create the suitable NER-token string (with the language-friendly terms). The input starts off with the padding token while the labels end on the sentence-end token <\\/s>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 40\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "input_sentences = []\n",
    "ner_translations_input = []\n",
    "ner_translations_labels = []\n",
    "\n",
    "input_sentences_t5 = []\n",
    "ner_translations_input_t5 = []\n",
    "ner_translations_labels_t5 = []\n",
    "\n",
    "# define masks for encode4r and decoder\n",
    "enc_in_masks = []\n",
    "dec_in_masks = []\n",
    "\n",
    "###\n",
    "\n",
    "train_input_sentences_t5 = []\n",
    "train_ner_translations_input_t5 = []\n",
    "train_ner_translations_labels_t5 = []\n",
    "\n",
    "train_enc_in_masks_t5 = []\n",
    "train_dec_in_masks_t5 = []\n",
    "\n",
    "###\n",
    "\n",
    "test_input_sentences_t5 = []\n",
    "test_ner_translations_input_t5 = []\n",
    "test_ner_translations_labels_t5 = []\n",
    "\n",
    "test_enc_in_masks_t5 = []\n",
    "test_dec_in_masks_t5 = []\n",
    "\n",
    "###\n",
    "\n",
    "with io.open(data_path + 'ner_dataset.csv', 'r', encoding='utf-8', errors='ignore') as train:\n",
    "    text = train.readlines()\n",
    "\n",
    "current_input = 'find entities:'\n",
    "current_translation = '<pad>'\n",
    "current_labels = ''\n",
    "\n",
    "for line_num, line in enumerate(text):\n",
    "    \n",
    "    cleanLine = re.sub(r'(?!(([^\"]*\"){2})*[^\"]*$),', '', line)  # deal with '\"10,000\"' and convert them to '10000' \n",
    "\n",
    "    sent, word, pos, ner = [x.strip('\\n') for x in cleanLine.split(',')]\n",
    "    #print(word, ner)\n",
    "    word = word.replace('\"\"\"\"', '\"')\n",
    "    word = word.replace('\"\"', '\"')\n",
    "    \n",
    "    if sent.startswith('Sentence:'):\n",
    "        current_input += ' </s>'\n",
    "        current_translation += ' </s>'\n",
    "        current_labels += ' </s>'\n",
    "        \n",
    "        input_sentences.append(current_input)\n",
    "        ner_translations_input.append(current_translation)\n",
    "        ner_translations_labels.append(current_labels)\n",
    "        \n",
    "        \n",
    "        current_input_ids = t5_tokenizer.encode(current_input)\n",
    "        len_input = len(current_input_ids)     \n",
    "        current_input_ids += ([0]* max_len)\n",
    "        current_input_ids = current_input_ids[:max_len]\n",
    "        \n",
    "        enc_in_mask = ([1] * len_input + [0] * max_len)[:max_len]\n",
    "        \n",
    "        current_translation_ids = t5_tokenizer.encode(current_translation)\n",
    "    \n",
    "        dec_in_length = len(current_translation_ids)\n",
    "        current_translation_ids += ([0]* max_len)\n",
    "        current_translation_ids = current_translation_ids[:max_len]\n",
    "        \n",
    "        dec_in_mask = ([1] * dec_in_length + [0] * max_len)[:max_len]\n",
    "        \n",
    "        current_labels_ids = t5_tokenizer.encode(current_labels)\n",
    "        current_labels_ids += ([0]* max_len)\n",
    "        current_labels_ids = current_labels_ids[:max_len]\n",
    "\n",
    "        input_sentences_t5.append(current_input_ids)\n",
    "        ner_translations_input_t5.append(current_translation_ids)\n",
    "        ner_translations_labels_t5.append(current_labels_ids)\n",
    "        \n",
    "        enc_in_masks.append(enc_in_mask)\n",
    "        dec_in_masks.append(dec_in_mask)\n",
    "        \n",
    "        if  np.random.random()< 0.8: \n",
    "            \n",
    "            ## train\n",
    "        \n",
    "            train_input_sentences_t5.append(current_input_ids)\n",
    "            train_ner_translations_input_t5.append(current_translation_ids)\n",
    "            train_ner_translations_labels_t5.append(current_labels_ids)\n",
    "\n",
    "            train_enc_in_masks_t5.append(enc_in_mask)\n",
    "            train_dec_in_masks_t5.append(dec_in_mask)\n",
    "        else:\n",
    "            \n",
    "            ## test\n",
    "\n",
    "            test_input_sentences_t5.append(current_input_ids)\n",
    "            test_ner_translations_input_t5.append(current_translation_ids)\n",
    "            test_ner_translations_labels_t5.append(current_labels_ids)\n",
    "\n",
    "            test_enc_in_masks_t5.append(enc_in_mask)\n",
    "            test_dec_in_masks_t5.append(dec_in_mask)\n",
    "        \n",
    "        current_input = '<pad> ' + 'find entities: ' + word\n",
    "        current_translation = '<pad> ' + tag_dict[ner]\n",
    "        current_labels = ''  + tag_dict[ner]\n",
    "        \n",
    "    \n",
    "    elif sent == '':\n",
    "        current_input += ' ' + word\n",
    "        current_translation += ' ' + tag_dict[ner]\n",
    "        current_labels += ' ' + tag_dict[ner]\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "input_sentences = input_sentences[2:]\n",
    "ner_translations_input = ner_translations_input[2:]\n",
    "ner_translations_labels = ner_translations_labels[2:]\n",
    "\n",
    "input_sentences_t5 = np.array(input_sentences_t5[2:])\n",
    "ner_translations_input_t5 = np.array(ner_translations_input_t5[2:])\n",
    "ner_translations_labels_t5 = np.array(ner_translations_labels_t5[2:])\n",
    "enc_in_masks_t5 = np.array(enc_in_masks[2:])\n",
    "dec_in_masks_t5 = np.array(dec_in_masks[2:])\n",
    "\n",
    "train_input_sentences_t5 = np.array(train_input_sentences_t5[2:])\n",
    "train_ner_translations_input_t5 = np.array(train_ner_translations_input_t5[2:])\n",
    "train_ner_translations_labels_t5 = np.array(train_ner_translations_labels_t5[2:])\n",
    "train_enc_in_masks_t5 = np.array(train_enc_in_masks_t5[2:])\n",
    "train_dec_in_masks_t5 = np.array(train_dec_in_masks_t5[2:])\n",
    "\n",
    "test_input_sentences_t5 = np.array(test_input_sentences_t5[2:])\n",
    "test_ner_translations_input_t5 = np.array(test_ner_translations_input_t5[2:])\n",
    "test_ner_translations_labels_t5 = np.array(test_ner_translations_labels_t5[2:])\n",
    "test_enc_in_masks_t5 = np.array(test_enc_in_masks_t5[2:])\n",
    "test_dec_in_masks_t5 = np.array(test_dec_in_masks_t5[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dec_in_masks_t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are examples of input sentence, decoder input string, and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_translations_input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_translations_labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check the corresponding encoder and decoder input masks that are supposed to mask outpad tokens: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_in_masks_t5[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(enc_in_masks_t5[1]) == len(t5_tokenizer.encode(input_sentences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_in_masks_t5[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(dec_in_masks_t5[1]) == len(t5_tokenizer.encode(ner_translations_input[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Masks have the right lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like before in the BERT architecture we define custom accuracies and custom loss functions:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_custom_acc_orig_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    accuracy across all non-padding/non-eos tokens. \n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    numNerClasses = y_pred.shape[-1]\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask =  (y_label > 1)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_custom_acc_orig_tokens_no_other(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    accuracy across all non-padding/non-eos tokens except for 'other'-token.\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    numNerClasses = y_pred.shape[-1]\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask_119 =  (y_label != 119)\n",
    "    #print('mask_119', mask_119)\n",
    "    mask_0 =  (y_label > 1)\n",
    "    #print('mask_0', mask_0)\n",
    "    mask =  tf.math.logical_and(mask_119, mask_0)\n",
    "    #print('mask', mask)\n",
    "    \n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_custom_acc_orig_tokens_begin_cont(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    accuracty for 'begin'- and 'continue'-tokens\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    numNerClasses = y_pred.shape[-1]\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    mask_916 =  (y_label == 916)\n",
    "    mask_1731 =  (y_label == 1731)\n",
    "    \n",
    "    begin_cont_mask = tf.math.logical_or(mask_916, mask_1731)\n",
    "    \n",
    "    #print('mask_119', mask_119)\n",
    "    mask_0 =  (y_label > 1)\n",
    "    #print('mask_0', mask_0)\n",
    "    mask =  tf.math.logical_and(begin_cont_mask, mask_0)\n",
    "    #print('mask', mask)\n",
    "    \n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_custom_acc_orig_tokens_not_begin_cont_other(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    accuracy for the actual non-'other' tokens, excluding also 'begin'- and 'continue'-tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    numNerClasses = y_pred.shape[-1]\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    mask_916 =  (y_label != 916)\n",
    "    mask_1731 =  (y_label != 1731)\n",
    "    mask_119 =  (y_label != 119)\n",
    "    \n",
    "    not_begin_cont_other_mask = tf.math.logical_and(tf.math.logical_and(mask_916, mask_1731), mask_119)\n",
    "    \n",
    "    #print('mask_119', mask_119)\n",
    "    mask_0 =  (y_label > 1)\n",
    "    #print('mask_0', mask_0)\n",
    "    mask =  tf.math.logical_and(not_begin_cont_other_mask, mask_0)\n",
    "    #print('mask', mask)\n",
    "    \n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a few tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.constant([[[0.5,0.2,0.3, 0.0], [0.1,0.7,0.2, 0.0], [0.1,0.3,0.6, 0.0], [0.1,0.3,0.0, 0.6]]])\n",
    "y_true = tf.constant([[1], [0], [2], [3]])\n",
    "\n",
    "t5_custom_acc_orig_tokens_no_other(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, let's define a custom loss function that removes padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss function explicitly, filtering out 'extra inserted labels'\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length + 1) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns:  cost\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    numNerClasses = y_pred.shape[-1]\n",
    "    \n",
    "    #print('numNerClasses', numNerClasses)\n",
    "    \n",
    "    y_label = tf.reshape(Flatten()(tf.cast(y_true, tf.int32)),[-1])\n",
    "    \n",
    "    mask = (y_label > 1)   # This mask is used to remove all tokens that do not correspond to the original base text.\n",
    "\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n",
    "    \n",
    "    y_flat_pred = tf.reshape(Flatten()(tf.cast(y_pred, tf.float32)),[-1, numNerClasses])\n",
    "    \n",
    "    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n",
    "    \n",
    "    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=True ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model consists of 3 inputs:\n",
    "\n",
    "* the input ids \n",
    "* the masks to mask out padding in the encoder\n",
    "* the decoder ids from the NER string\n",
    "\n",
    "We then use the **TFT5ForConditionalGeneration** model to implement our task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_keras_model():\n",
    "    \n",
    "    \n",
    "    encode_in = tf.keras.layers.Input(shape=(max_len,), dtype='int32', name=\"encode_in_ids\")\n",
    "    enc_mask_in = tf.keras.layers.Input(shape=(max_len,), dtype='int32', name=\"enc_mask_in_ids\")\n",
    "    decode_in = tf.keras.layers.Input(shape=(None,), dtype='int32', name=\"decode_in_ids\")\n",
    "    dec_mask_in = tf.keras.layers.Input(shape=(None,), dtype='int32', name=\"dec_mask_in_ids\")\n",
    "    \n",
    "    t5_layer = TFT5ForConditionalGeneration.from_pretrained(t5_model)\n",
    "    \n",
    "    t5_out = t5_layer({'input_ids': encode_in, \n",
    "                       'decoder_input_ids':decode_in, \n",
    "                       'attention_mask':enc_mask_in,\n",
    "                       'decoder_attention_mask':dec_mask_in\n",
    "                      }, \n",
    "                             return_dict=True)\n",
    "    \n",
    "    pred_logits = t5_out['logits']\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[encode_in, \n",
    "                                          enc_mask_in, \n",
    "                                          decode_in,\n",
    "                                          dec_mask_in\n",
    "                                         ], \n",
    "                                  outputs=pred_logits)\n",
    "\n",
    "    model.compile(loss=t5_custom_loss, \n",
    "                  optimizer=tf.keras.optimizers.Adam(), \n",
    "                  metrics=[\n",
    "                  #     tf.keras.metrics.Accuracy(),\n",
    "                          t5_custom_acc_orig_tokens, \n",
    "                           t5_custom_acc_orig_tokens_no_other,\n",
    "                      t5_custom_acc_orig_tokens_begin_cont,\n",
    "                      t5_custom_acc_orig_tokens_not_begin_cont_other\n",
    "                  #\n",
    "                  ]\n",
    "                 )\n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "try:\n",
    "    del t5_ner_model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "t5_ner_model = t5_keras_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we have about 60m parameters.\n",
    "\n",
    "We now use Keras to fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off = 20000000\n",
    "\n",
    "t5_ner_model.fit([train_input_sentences_t5[:cut_off], \n",
    "                      train_enc_in_masks_t5[:cut_off], \n",
    "                      train_ner_translations_input_t5[:cut_off],\n",
    "                      train_dec_in_masks_t5[:cut_off]\n",
    "                     ],\n",
    "                   train_ner_translations_labels_t5[:cut_off],\n",
    "                 validation_data=([test_input_sentences_t5[:cut_off],\n",
    "                                   test_enc_in_masks_t5[:cut_off], \n",
    "                                   test_ner_translations_input_t5[:cut_off],\n",
    "                                   test_dec_in_masks_t5[:cut_off]],\n",
    "                                test_ner_translations_labels_t5[:cut_off]),\n",
    "                 batch_size=8,\n",
    "                epochs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great! It learned, and the test accuracies are well into the 90% range!  But be careful... the metrics above have been achieved with **teacher-forcing**. In actual inference mode where you do not force the correct input at each decoder time-step, but instead generate the the NER-token step by step, any error will affect the next prediction. This will likely increase the error rate noticeably.\n",
    "\n",
    "**Question for the Reader:** *can you write code that calculates actual accuracies, i.e., generates the NER tokens token-by-token in inference mode?*\n",
    "\n",
    "\n",
    "For now, we leave it as an exercise to the reader to write the corresponding inference loop (using past key values, etc.) and to compare the results using T5 with the those of the BERT model quoted earlier in this paper. \n",
    "\n",
    "But either way, the main point is established: the architecture learns reasonably well and the results are far from random. And most importantly, we hope that these steps help you to **get started with T5.** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
