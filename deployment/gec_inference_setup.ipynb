{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEC Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting awscli\n",
      "  Downloading awscli-1.30.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting botocore==1.32.6 (from awscli)\n",
      "  Downloading botocore-1.32.6-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: docutils<0.17,>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from awscli) (0.15.2)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from awscli) (0.7.0)\n",
      "Requirement already satisfied: PyYAML<6.1,>=3.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from awscli) (6.0.1)\n",
      "Requirement already satisfied: colorama<0.4.5,>=0.2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from awscli) (0.4.4)\n",
      "Requirement already satisfied: rsa<4.8,>=3.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from awscli) (4.7.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore==1.32.6->awscli) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore==1.32.6->awscli) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore==1.32.6->awscli) (1.26.18)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rsa<4.8,>=3.1.2->awscli) (0.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.32.6->awscli) (1.16.0)\n",
      "Downloading awscli-1.30.6-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.32.6-py3-none-any.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore, awscli\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.80\n",
      "    Uninstalling botocore-1.31.80:\n",
      "      Successfully uninstalled botocore-1.31.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "boto3 1.28.80 requires botocore<1.32.0,>=1.31.80, but you have botocore 1.32.6 which is incompatible.\u001b[0m\u001b[31m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed awscli-1.30.6 botocore-1.32.6\n",
      "Requirement already satisfied: q in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.7)\n",
      "Requirement already satisfied: sagemaker-ssh-helper in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: sagemaker>=2.145.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-ssh-helper) (2.197.0)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-ssh-helper) (5.9.5)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (1.28.80)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (1.26.1)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (4.23.4)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (6.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (1.5.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (0.3.1)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (4.19.1)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (3.11.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (1.7.0)\n",
      "Collecting botocore<1.32.0,>=1.31.80 (from boto3<2.0,>=1.26.131->sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading botocore-1.31.85-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker>=2.145.0->sagemaker-ssh-helper) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker>=2.145.0->sagemaker-ssh-helper) (0.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker>=2.145.0->sagemaker-ssh-helper) (3.17.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->sagemaker>=2.145.0->sagemaker-ssh-helper) (3.1.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker>=2.145.0->sagemaker-ssh-helper) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker>=2.145.0->sagemaker-ssh-helper) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker>=2.145.0->sagemaker-ssh-helper) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker>=2.145.0->sagemaker-ssh-helper) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker>=2.145.0->sagemaker-ssh-helper) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker>=2.145.0->sagemaker-ssh-helper) (2023.3.post1)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker>=2.145.0->sagemaker-ssh-helper) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker>=2.145.0->sagemaker-ssh-helper) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker>=2.145.0->sagemaker-ssh-helper) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker>=2.145.0->sagemaker-ssh-helper) (0.70.15)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from schema->sagemaker>=2.145.0->sagemaker-ssh-helper) (21.6.0)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.80->boto3<2.0,>=1.26.131->sagemaker>=2.145.0->sagemaker-ssh-helper) (1.26.18)\n",
      "Downloading botocore-1.31.85-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.32.6\n",
      "    Uninstalling botocore-1.32.6:\n",
      "      Successfully uninstalled botocore-1.32.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.30.6 requires botocore==1.32.6, but you have botocore 1.31.85 which is incompatible.\u001b[0m\u001b[31m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed botocore-1.31.85\n",
      "sagemaker-ssh-helper==2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# pip uninstall -y -q awscli\n",
    "pip install awscli\n",
    "pip install q -U sagemaker-ssh-helper\n",
    "pip freeze | grep sagemaker-ssh-helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ssh_notebook.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ssh_notebook.py\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import sagemaker_ssh_helper\n",
    "sagemaker_ssh_helper.setup_and_start_ssh()\n",
    "\n",
    "while os.environ.get(\"START_SSH\", \"false\") == \"true\":\n",
    "    time.sleep(10)  # will sleep forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm-ssh-notebook: SSH owner user ID is already set in ~/.sm-ssh-owner, skipping override\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "LOCAL_USER_ID=\"AIDAYKGQHXPC6C3H7TY32\"  # replace with your local UserId\n",
    "\n",
    "if [ -f ~/.sm-ssh-owner ]; then\n",
    "    echo \"sm-ssh-notebook: SSH owner user ID is already set in ~/.sm-ssh-owner, skipping override\"\n",
    "else\n",
    "    echo \"sm-ssh-notebook: Saving SSH owner user ID into ~/.sm-ssh-owner\"\n",
    "    echo \"$LOCAL_USER_ID\" > ~/.sm-ssh-owner\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.expanduser('~/.sm-ssh-owner')) as f:\n",
    "    local_user_id = f.readline().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "arn:aws:iam::571667364805:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from utils import Config\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from model_utils import download_simple_model\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pprint\n",
    "\n",
    "from sagemaker_ssh_helper.wrapper import SSHEstimatorWrapper\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "s3 = boto3.resource('s3')\n",
    "region = boto3.Session().region_name\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "\n",
    "# The name of our algorithm -- i.e. the name of the inference container\n",
    "INFERENCE_ALGORITHM_NAME = \"sm-gec-aws\"\n",
    "ENDPOINT_NAME = \"sm-gec-aws\"\n",
    "IMAGE_URI_INFERENCE = (\n",
    "    f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{INFERENCE_ALGORITHM_NAME}:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GEC - Inference Endpoint Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports And Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed huggingface-hub-0.19.4 regex-2023.10.3 safetensors-0.4.0 tokenizers-0.15.0 transformers-4.35.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb tensorflow transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow sagemaker wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple GEC specific constants\n",
    "RUN_TO_DEPLOY = '3emhdbgu' # The wandb run from which to get model weights\n",
    "S3_BUCKET = 'project-langbot-models'\n",
    "S3_DATA_KEY = f'gec_simple_model_{RUN_TO_DEPLOY}_weights.gz'\n",
    "PRETRAINED_MODEL_DATA = 's3://{}/{}'.format(S3_BUCKET, S3_DATA_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Push Model Weights To S3 From WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload the model weights from WandB to S3 bucket\n",
    "def copy_weights_to_s3(runid, download=True):\n",
    "    main_args = Config()\n",
    "    run_ref = main_args.SIMPLE_MODEL_RUNS[runid]\n",
    "    weights_filename = 'model_weights.gz'\n",
    "    if download:\n",
    "        download_simple_model(run_ref, weights_filename)\n",
    "    # Push the downloaded weights to s3 bucket\n",
    "    role = get_execution_role()\n",
    "    s3.meta.client.upload_file(f'downloads/{weights_filename}', S3_BUCKET, S3_DATA_KEY)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found <Run langbot/langbot_gec_plain_top_performers/3emhdbgu (finished)> to load artifact from\n",
      "Downloading model_weights.gz\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "copy_weights_to_s3(RUN_TO_DEPLOY, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://project-langbot-models/gec_simple_model_3emhdbgu_weights.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s3.Object(bucket_name='project-langbot-models', key='gec_simple_model_3emhdbgu_weights.gz')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm model weights are there on S3\n",
    "print(PRETRAINED_MODEL_DATA)\n",
    "s3.Bucket(S3_BUCKET).Object(S3_DATA_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DockerFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Based on\n",
      "# https://github.com/aws/amazon-sagemaker-examples/blob/main/advanced_functionality/tensorflow_iris_byom/tensorflow_BYOM_iris.ipynb\n",
      "\n",
      "ARG REGION=us-west-2\n",
      "\n",
      "# SageMaker TF image for INFERENCE\n",
      "FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/tensorflow-inference:2.12.1-gpu-py310-cu118-ubuntu20.04-sagemaker\n",
      "\n",
      "ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      "\n",
      "# /opt/ml and all subdirectories are utilized by SageMaker, we use the /code subdirectory to store our user code.\n",
      "COPY /gec /opt/ml/code\n",
      "\n",
      "# this environment variable is used by the SageMaker TensorFlow container to determine our user code directory.\n",
      "ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      "\n",
      "# this environment variable is used by the SageMaker Tensorflow container to determine our program entry point\n",
      "# for training and serving.\n",
      "# For more information: https://github.com/aws/sagemaker-tensorflow-training-toolkit\n",
      "ENV SAGEMAKER_PROGRAM gec-simple-inference.py\n",
      "\n",
      "RUN pip install --no-cache-dir --upgrade pip && \\\n",
      "    pip install --no-cache-dir protobuf==3.20.* && \\\n",
      "    pip install --no-cache-dir nvgpu smdebug transformers sentencepiece seqeval wandb sagemaker-ssh-helper\n",
      "\n",
      "RUN pip freeze\n"
     ]
    }
   ],
   "source": [
    "!cat model-simple/container/Dockerfile-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inference script - gec-simple-inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mConfig\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel_utils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m create_simple_model, infer_simple\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "JSON_CONTENT_TYPE = \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "logger.setLevel(logging.DEBUG)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m====================== Running stuff ============================\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_model_from_run_3emhdbgu\u001b[39;49;00m(weights_loc):\u001b[37m\u001b[39;49;00m\n",
      "    main_args = Config()\u001b[37m\u001b[39;49;00m\n",
      "    train_config = main_args.bert_plain_models[\u001b[34m0\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    optimizer = tf.keras.optimizers.AdamW(\u001b[37m\u001b[39;49;00m\n",
      "        learning_rate=\u001b[34m5e-5\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        weight_decay=\u001b[34m0.005\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        beta_1=\u001b[34m0.9\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        beta_2=\u001b[34m0.999\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        epsilon=\u001b[34m1e-07\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        amsgrad=\u001b[34mFalse\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    train_config[\u001b[33m'\u001b[39;49;00m\u001b[33moptimizer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = optimizer\u001b[37m\u001b[39;49;00m\n",
      "    train_config[\u001b[33m'\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[34m32\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_config[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain_layers\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = -\u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_config[\u001b[33m'\u001b[39;49;00m\u001b[33mepochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[34m10\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_config[\u001b[33m'\u001b[39;49;00m\u001b[33mdropout_rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[34m0.5\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_config[\u001b[33m'\u001b[39;49;00m\u001b[33mload_from_pretrained\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_config[\u001b[33m'\u001b[39;49;00m\u001b[33mexport_weights\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[34mFalse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_config[\u001b[33m'\u001b[39;49;00m\u001b[33mweights_loc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = weights_loc\u001b[37m\u001b[39;49;00m\n",
      "    train_config[\u001b[33m'\u001b[39;49;00m\u001b[33mextra_metrics_to_wandb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[34mFalse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_config[\u001b[33m'\u001b[39;49;00m\u001b[33mpublish_weights_to_wandb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[34mFalse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_config[\u001b[33m'\u001b[39;49;00m\u001b[33muse_weighted_loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_config[\u001b[33m'\u001b[39;49;00m\u001b[33menable_wandb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[34mFalse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_config[\u001b[33m'\u001b[39;49;00m\u001b[33mpretrain_model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[34mFalse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    model = create_simple_model(main_args, train_config, verbosity=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    tokenizer = AutoTokenizer.from_pretrained(train_config[\u001b[33m'\u001b[39;49;00m\u001b[33mmodel_name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m  model, tokenizer\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33minside model_fn, model_dir= \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel_dir\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    device = \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mDevice Type: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(device))\u001b[37m\u001b[39;49;00m\n",
      "    weights_loc = \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/temp\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m os.path.exists(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mweights_loc\u001b[33m}\u001b[39;49;00m\u001b[33m/checkpoint\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        logging.error(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mMissing model weights file file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mweights_loc\u001b[33m}\u001b[39;49;00m\u001b[33m/checkpoint\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Create the model and load weights\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# The model configuration needs to match the exact model that produced the weights.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# If the model is retrained and new weights are used the the model architecture needs to change as well.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    model, tokenizer = _load_model_from_run_3emhdbgu()\u001b[37m\u001b[39;49;00m\n",
      "    model.to(device)\u001b[37m\u001b[39;49;00m\n",
      "    logging.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mGEC model loaded into device \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mdevice\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m model, tokenizer\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(data, model_tokenizer):\u001b[37m\u001b[39;49;00m\n",
      "    model, tokenizer = model_tokenizer\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mGot input Data: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mdata\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m infer_simple(model, tokenizer, data)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(serialized_input_data, content_type=JSON_CONTENT_TYPE):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mserialized_input_data object: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mserialized_input_data\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == JSON_CONTENT_TYPE:\u001b[37m\u001b[39;49;00m\n",
      "        input_data = json.loads(serialized_input_data)\u001b[37m\u001b[39;49;00m\n",
      "        logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33minput_data object: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00minput_data\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m [input_data[\u001b[33m'\u001b[39;49;00m\u001b[33mline\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in Accept: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + content_type)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(prediction, content_type):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mprediction object before: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprediction\u001b[33m}\u001b[39;49;00m\u001b[33m, type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mtype\u001b[39;49;00m(prediction)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Transform predictions to JSON\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    prediction_result = {\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33moutput\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: prediction[\u001b[34m0\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    }\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mprediction_result object: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprediction_result\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m prediction_result\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize model-simple/container/gec/gec-simple-inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build and Push Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/model_gec_ram/deployment\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECR image fullname: 571667364805.dkr.ecr.us-west-2.amazonaws.com/sm-gec-aws:latest\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  19.97kB\n",
      "Step 1/8 : ARG REGION=us-west-2\n",
      "Step 2/8 : FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/tensorflow-inference:2.12.1-gpu-py310-cu118-ubuntu20.04-sagemaker\n",
      " ---> fde65ca56ee6\n",
      "Step 3/8 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> ca345d8b1c1c\n",
      "Step 4/8 : COPY /gec /opt/ml/code\n",
      " ---> a45876d5d3de\n",
      "Step 5/8 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Running in 49c976bea365\n",
      "Removing intermediate container 49c976bea365\n",
      " ---> fd4c9e2ed716\n",
      "Step 6/8 : ENV SAGEMAKER_PROGRAM gec-simple-inference.py\n",
      " ---> Running in f1168f61b1b8\n",
      "Removing intermediate container f1168f61b1b8\n",
      " ---> beb18677ee20\n",
      "Step 7/8 : RUN pip install --no-cache-dir --upgrade pip &&     pip install --no-cache-dir protobuf==3.20.* &&     pip install --no-cache-dir nvgpu smdebug transformers numba sentencepiece seqeval wandb sagemaker-ssh-helper\n",
      " ---> Running in 0d2769465834\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/site-packages (23.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 36.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.1.2\n",
      "    Uninstalling pip-23.1.2:\n",
      "      Successfully uninstalled pip-23.1.2\n",
      "Successfully installed pip-23.3.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRequirement already satisfied: protobuf==3.20.* in /usr/local/lib/python3.10/site-packages (3.20.3)\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mCollecting nvgpu\n",
      "  Downloading nvgpu-0.10.0.tar.gz (8.4 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting smdebug\n",
      "  Downloading smdebug-1.0.34-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.5/123.5 kB 9.1 MB/s eta 0:00:00\n",
      "Collecting numba\n",
      "  Downloading numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 48.8 MB/s eta 0:00:00\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 194.4 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting sagemaker-ssh-helper\n",
      "  Downloading sagemaker_ssh_helper-2.1.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting ansi2html (from nvgpu)\n",
      "  Downloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\n",
      "Collecting arrow (from nvgpu)\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting flask (from nvgpu)\n",
      "  Downloading flask-3.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting flask-restful (from nvgpu)\n",
      "  Downloading Flask_RESTful-0.3.10-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting pandas (from nvgpu)\n",
      "  Downloading pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting psutil (from nvgpu)\n",
      "  Downloading psutil-5.9.6-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from nvgpu) (2.27.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/site-packages (from nvgpu) (1.16.0)\n",
      "Collecting termcolor (from nvgpu)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting tabulate (from nvgpu)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting pynvml (from nvgpu)\n",
      "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 198.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf<=3.20.3,>=3.20.0 in /usr/local/lib/python3.10/site-packages (from smdebug) (3.20.3)\n",
      "Collecting numpy>=1.16.0 (from smdebug)\n",
      "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 248.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from smdebug) (23.1)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /usr/local/lib/python3.10/site-packages (from smdebug) (1.26.135)\n",
      "Collecting pyinstrument==3.4.2 (from smdebug)\n",
      "  Downloading pyinstrument-3.4.2-py2.py3-none-any.whl (83 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.3/83.3 kB 242.7 MB/s eta 0:00:00\n",
      "Collecting pyinstrument-cext>=0.2.2 (from pyinstrument==3.4.2->smdebug)\n",
      "  Downloading pyinstrument_cext-0.2.4.tar.gz (4.8 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers) (5.4.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 91.3 MB/s eta 0:00:00\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.6/57.6 kB 225.5 MB/s eta 0:00:00\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba)\n",
      "  Downloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting scikit-learn>=0.21.3 (from seqeval)\n",
      "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting Click!=8.0.0,>=7.1 (from wandb)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.37.1-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from wandb) (67.7.2)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting sagemaker>=2.145.0 (from sagemaker-ssh-helper)\n",
      "  Downloading sagemaker-2.197.0.tar.gz (917 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 917.0/917.0 kB 74.7 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.135 in /usr/local/lib/python3.10/site-packages (from boto3>=1.10.32->smdebug) (1.29.135)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/site-packages (from boto3>=1.10.32->smdebug) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/site-packages (from boto3>=1.10.32->smdebug) (0.6.1)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->transformers)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.16.4->transformers)\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->nvgpu) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->nvgpu) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests->nvgpu) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->nvgpu) (3.4)\n",
      "Collecting attrs<24,>=23.1.0 (from sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 227.5 MB/s eta 0:00:00\n",
      "Collecting cloudpickle==2.2.1 (from sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting google-pasta (from sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 197.1 MB/s eta 0:00:00\n",
      "Collecting smdebug-rulesconfig==1.0.1 (from sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading importlib_metadata-6.8.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pathos (from sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading pathos-0.3.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting schema (from sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting jsonschema (from sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading jsonschema-4.20.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting platformdirs (from sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading platformdirs-4.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tblib==1.7.0 (from sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.4/60.4 kB 248.4 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/site-packages (from arrow->nvgpu) (2.8.2)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow->nvgpu)\n",
      "  Downloading types_python_dateutil-2.8.19.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting Werkzeug>=3.0.0 (from flask->nvgpu)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting Jinja2>=3.1.2 (from flask->nvgpu)\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 kB 166.2 MB/s eta 0:00:00\n",
      "Collecting itsdangerous>=2.1.2 (from flask->nvgpu)\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting blinker>=1.6.2 (from flask->nvgpu)\n",
      "  Downloading blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting aniso8601>=0.82 (from flask-restful->nvgpu)\n",
      "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 189.5 MB/s eta 0:00:00\n",
      "Collecting pytz (from flask-restful->nvgpu)\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas->nvgpu)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 341.8/341.8 kB 218.9 MB/s eta 0:00:00\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<7.0,>=1.4.0->sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2>=3.1.2->flask->nvgpu)\n",
      "  Downloading MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading jsonschema_specifications-2023.11.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading referencing-0.31.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading rpds_py-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting ppft>=1.7.6.7 (from pathos->sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading ppft-1.7.6.7-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dill>=0.3.7 (from pathos->sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting pox>=0.3.3 (from pathos->sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading pox-0.3.3-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting multiprocess>=0.70.15 (from pathos->sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting contextlib2>=0.5.5 (from schema->sagemaker>=2.145.0->sagemaker-ssh-helper)\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading smdebug-1.0.34-py2.py3-none-any.whl (280 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 280.1/280.1 kB 306.5 MB/s eta 0:00:00\n",
      "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 209.4 MB/s eta 0:00:00\n",
      "Downloading numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 258.9 MB/s eta 0:00:00\n",
      "Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 224.5 MB/s eta 0:00:00\n",
      "Downloading sagemaker_ssh_helper-2.1.0-py3-none-any.whl (70 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.0/71.0 kB 245.2 MB/s eta 0:00:00\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 255.9 MB/s eta 0:00:00\n",
      "Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.6/190.6 kB 113.8 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 311.7/311.7 kB 315.3 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 MB 169.8 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 217.8 MB/s eta 0:00:00\n",
      "Downloading psutil-5.9.6-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 283.6/283.6 kB 241.1 MB/s eta 0:00:00\n",
      "Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 773.9/773.9 kB 130.7 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 82.1 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 705.5/705.5 kB 220.2 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.8/10.8 MB 213.1 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-1.37.1-py2.py3-none-any.whl (251 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 251.7/251.7 kB 207.7 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 161.8 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.3/78.3 kB 267.9 MB/s eta 0:00:00\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.4/66.4 kB 255.2 MB/s eta 0:00:00\n",
      "Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading flask-3.0.0-py3-none-any.whl (99 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.7/99.7 kB 241.5 MB/s eta 0:00:00\n",
      "Downloading Flask_RESTful-0.3.10-py2.py3-none-any.whl (26 kB)\n",
      "Downloading pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 182.9 MB/s eta 0:00:00\n",
      "Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 166.4/166.4 kB 49.4 MB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 211.6 MB/s eta 0:00:00\n",
      "Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.2/302.2 kB 264.2 MB/s eta 0:00:00\n",
      "Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 502.5/502.5 kB 177.6 MB/s eta 0:00:00\n",
      "Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.4/36.4 MB 207.1 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Downloading types_python_dateutil-2.8.19.14-py3-none-any.whl (9.4 kB)\n",
      "Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 226.7/226.7 kB 254.3 MB/s eta 0:00:00\n",
      "Downloading jsonschema-4.20.0-py3-none-any.whl (84 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.7/84.7 kB 268.7 MB/s eta 0:00:00\n",
      "Downloading pathos-0.3.1-py3-none-any.whl (82 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.1/82.1 kB 176.7 MB/s eta 0:00:00\n",
      "Downloading platformdirs-4.0.0-py3-none-any.whl (17 kB)\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 115.3/115.3 kB 291.0 MB/s eta 0:00:00\n",
      "Downloading jsonschema_specifications-2023.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.8/134.8 kB 226.3 MB/s eta 0:00:00\n",
      "Downloading pox-0.3.3-py3-none-any.whl (29 kB)\n",
      "Downloading ppft-1.7.6.7-py3-none-any.whl (56 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.8/56.8 kB 133.9 MB/s eta 0:00:00\n",
      "Downloading referencing-0.31.0-py3-none-any.whl (25 kB)\n",
      "Downloading rpds_py-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 207.3 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Building wheels for collected packages: nvgpu, seqeval, sagemaker, pyinstrument-cext\n",
      "  Building wheel for nvgpu (pyproject.toml): started\n",
      "  Building wheel for nvgpu (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for nvgpu: filename=nvgpu-0.10.0-py3-none-any.whl size=9543 sha256=f402c4555272a8650264109e85f2dabd88e53f4045fcfc3a489fa2050f826a13\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7i015d66/wheels/e2/c4/73/829a16caa9c3a3b6a0d16985c18d8c3b59c3812d1055552d8e\n",
      "  Building wheel for seqeval (pyproject.toml): started\n",
      "  Building wheel for seqeval (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=c83a0765e15e4cb9934b0aee32a79007fbadef0bc711d452c3bf0ee5546a8b89\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7i015d66/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "  Building wheel for sagemaker (pyproject.toml): started\n",
      "  Building wheel for sagemaker (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.197.0-py2.py3-none-any.whl size=1223348 sha256=ea6e2223c4faa198d8f4c91ed1911d5910e43d4383134e4973e7c89eb35f5777\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7i015d66/wheels/dc/44/04/ab05503d4399b4be500dec0dc7e64fe536927c23301f99eafd\n",
      "  Building wheel for pyinstrument-cext (pyproject.toml): started\n",
      "  Building wheel for pyinstrument-cext (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyinstrument-cext: filename=pyinstrument_cext-0.2.4-cp310-cp310-linux_x86_64.whl size=20425 sha256=c8f8cd4ad281b567b6713dff2f56cb0a10efa29883243615b64fd4c11a1d1c51\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7i015d66/wheels/0f/8b/7a/5f7fd1dd6d3cbb3d350d4c832c5e2f962687749f6d67d573a6\n",
      "Successfully built nvgpu seqeval sagemaker pyinstrument-cext\n",
      "Installing collected packages: types-python-dateutil, sentencepiece, pytz, pyinstrument-cext, appdirs, aniso8601, zipp, tzdata, typing-extensions, tqdm, threadpoolctl, termcolor, tblib, tabulate, smmap, smdebug-rulesconfig, setproctitle, sentry-sdk, safetensors, rpds-py, regex, pyyaml, pynvml, pyinstrument, psutil, ppft, pox, platformdirs, numpy, MarkupSafe, llvmlite, joblib, itsdangerous, google-pasta, fsspec, filelock, docker-pycreds, dill, contextlib2, cloudpickle, Click, blinker, attrs, ansi2html, Werkzeug, scipy, schema, referencing, pandas, numba, multiprocess, Jinja2, importlib-metadata, huggingface-hub, gitdb, arrow, tokenizers, scikit-learn, pathos, jsonschema-specifications, GitPython, flask, wandb, transformers, seqeval, jsonschema, flask-restful, smdebug, sagemaker, nvgpu, sagemaker-ssh-helper\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.135 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0.1 which is incompatible.\n",
      "\u001b[0mSuccessfully installed Click-8.1.7 GitPython-3.1.40 Jinja2-3.1.2 MarkupSafe-2.1.3 Werkzeug-3.0.1 aniso8601-9.0.1 ansi2html-1.8.0 appdirs-1.4.4 arrow-1.3.0 attrs-23.1.0 blinker-1.7.0 cloudpickle-2.2.1 contextlib2-21.6.0 dill-0.3.7 docker-pycreds-0.4.0 filelock-3.13.1 flask-3.0.0 flask-restful-0.3.10 fsspec-2023.10.0 gitdb-4.0.11 google-pasta-0.2.0 huggingface-hub-0.19.4 importlib-metadata-6.8.0 itsdangerous-2.1.2 joblib-1.3.2 jsonschema-4.20.0 jsonschema-specifications-2023.11.1 llvmlite-0.41.1 multiprocess-0.70.15 numba-0.58.1 numpy-1.26.2 nvgpu-0.10.0 pandas-2.1.3 pathos-0.3.1 platformdirs-4.0.0 pox-0.3.3 ppft-1.7.6.7 psutil-5.9.6 pyinstrument-3.4.2 pyinstrument-cext-0.2.4 pynvml-11.5.0 pytz-2023.3.post1 pyyaml-6.0.1 referencing-0.31.0 regex-2023.10.3 rpds-py-0.13.1 safetensors-0.4.0 sagemaker-2.197.0 sagemaker-ssh-helper-2.1.0 schema-0.7.5 scikit-learn-1.3.2 scipy-1.11.4 sentencepiece-0.1.99 sentry-sdk-1.37.1 seqeval-1.2.2 setproctitle-1.3.3 smdebug-1.0.34 smdebug-rulesconfig-1.0.1 smmap-5.0.1 tabulate-0.9.0 tblib-1.7.0 termcolor-2.3.0 threadpoolctl-3.2.0 tokenizers-0.15.0 tqdm-4.66.1 transformers-4.35.2 types-python-dateutil-2.8.19.14 typing-extensions-4.8.0 tzdata-2023.3 wandb-0.16.0 zipp-3.17.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 0d2769465834\n",
      " ---> c3f7398be53b\n",
      "Step 8/8 : RUN pip freeze\n",
      " ---> Running in 6a650db7be12\n",
      "aniso8601==9.0.1\n",
      "ansi2html==1.8.0\n",
      "appdirs==1.4.4\n",
      "arrow==1.3.0\n",
      "attrs==23.1.0\n",
      "awscli==1.27.135\n",
      "blinker==1.7.0\n",
      "boto3==1.26.135\n",
      "botocore==1.29.135\n",
      "certifi==2023.5.7\n",
      "charset-normalizer==2.0.12\n",
      "click==8.1.7\n",
      "cloudpickle==2.2.1\n",
      "colorama==0.4.4\n",
      "contextlib2==21.6.0\n",
      "Cython==0.29.30\n",
      "dill==0.3.7\n",
      "docker-pycreds==0.4.0\n",
      "docutils==0.16\n",
      "falcon==3.0.1\n",
      "filelock==3.13.1\n",
      "Flask==3.0.0\n",
      "Flask-RESTful==0.3.10\n",
      "fsspec==2023.10.0\n",
      "gevent==21.12.0\n",
      "gitdb==4.0.11\n",
      "GitPython==3.1.40\n",
      "google-pasta==0.2.0\n",
      "greenlet==1.1.3.post0\n",
      "grpcio==1.46.3\n",
      "gunicorn==20.1.0\n",
      "huggingface-hub==0.19.4\n",
      "idna==3.4\n",
      "importlib-metadata==6.8.0\n",
      "itsdangerous==2.1.2\n",
      "Jinja2==3.1.2\n",
      "jmespath==1.0.1\n",
      "joblib==1.3.2\n",
      "jsonschema==4.20.0\n",
      "jsonschema-specifications==2023.11.1\n",
      "llvmlite==0.41.1\n",
      "MarkupSafe==2.1.3\n",
      "multiprocess==0.70.15\n",
      "numba==0.58.1\n",
      "numpy==1.26.2\n",
      "nvgpu==0.10.0\n",
      "packaging==23.1\n",
      "pandas==2.1.3\n",
      "pathos==0.3.1\n",
      "platformdirs==4.0.0\n",
      "pox==0.3.3\n",
      "ppft==1.7.6.7\n",
      "protobuf==3.20.3\n",
      "psutil==5.9.6\n",
      "pyasn1==0.5.0\n",
      "pyinstrument==3.4.2\n",
      "pyinstrument-cext==0.2.4\n",
      "pynvml==11.5.0\n",
      "python-dateutil==2.8.2\n",
      "pytz==2023.3.post1\n",
      "PyYAML==6.0.1\n",
      "referencing==0.31.0\n",
      "regex==2023.10.3\n",
      "requests==2.27.1\n",
      "rpds-py==0.13.1\n",
      "rsa==4.7.2\n",
      "s3transfer==0.6.1\n",
      "safetensors==0.4.0\n",
      "sagemaker==2.197.0\n",
      "sagemaker-ssh-helper==2.1.0\n",
      "schema==0.7.5\n",
      "scikit-learn==1.3.2\n",
      "scipy==1.11.4\n",
      "sentencepiece==0.1.99\n",
      "sentry-sdk==1.37.1\n",
      "seqeval==1.2.2\n",
      "setproctitle==1.3.3\n",
      "six==1.16.0\n",
      "smdebug==1.0.34\n",
      "smdebug-rulesconfig==1.0.1\n",
      "smmap==5.0.1\n",
      "tabulate==0.9.0\n",
      "tblib==1.7.0\n",
      "tensorflow-serving-api-gpu==2.12.1\n",
      "termcolor==2.3.0\n",
      "threadpoolctl==3.2.0\n",
      "tokenizers==0.15.0\n",
      "tqdm==4.66.1\n",
      "transformers==4.35.2\n",
      "types-python-dateutil==2.8.19.14\n",
      "typing_extensions==4.8.0\n",
      "tzdata==2023.3\n",
      "urllib3==1.26.15\n",
      "wandb==0.16.0\n",
      "Werkzeug==3.0.1\n",
      "zipp==3.17.0\n",
      "zope.event==4.6\n",
      "zope.interface==6.0\n",
      "Removing intermediate container 6a650db7be12\n",
      " ---> a5bd366b3b0d\n",
      "Successfully built a5bd366b3b0d\n",
      "Successfully tagged sm-gec-aws:latest\n",
      "The push refers to repository [571667364805.dkr.ecr.us-west-2.amazonaws.com/sm-gec-aws]\n",
      "\n",
      "\u001b[1Bfb7302fa: Preparing \n",
      "\u001b[1Bdce21472: Preparing \n",
      "\u001b[1B6cfb3167: Preparing \n",
      "\u001b[1B7575fae0: Preparing \n",
      "\u001b[1B7fc65bc2: Preparing \n",
      "\u001b[1B65e0fd45: Preparing \n",
      "\u001b[1Be2696bb8: Preparing \n",
      "\u001b[1B1becb391: Preparing \n",
      "\u001b[1Be6e6bad0: Preparing \n",
      "\u001b[1B7ac9d18b: Preparing \n",
      "\u001b[1Bedcde126: Preparing \n",
      "\u001b[1B7ebab9f5: Preparing \n",
      "\u001b[1B28bfd596: Preparing \n",
      "\u001b[1B77cc4166: Preparing \n",
      "\u001b[1B1cfdf474: Preparing \n",
      "\u001b[1B659733f0: Preparing \n",
      "\u001b[1B0bf54747: Preparing \n",
      "\u001b[1B89de37f2: Preparing \n",
      "\u001b[1Bc1df018a: Preparing \n",
      "\u001b[1B2d1cfdaf: Preparing \n",
      "\u001b[1B0423988f: Preparing \n",
      "\u001b[1B7c4de29d: Preparing \n",
      "\u001b[1Becc50864: Preparing \n",
      "\u001b[1B7e3e56a9: Preparing \n",
      "\u001b[1B7e76bf1b: Preparing \n",
      "\u001b[1Ba70ab1cd: Preparing \n",
      "\u001b[1B48c52364: Preparing \n",
      "\u001b[24Bfc65bc2: Retrying in 1 second   [26A\u001b[2K\u001b[28A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[24A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[27A\u001b[2K\u001b[24A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[24A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[24A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[27A\u001b[2K\u001b[24A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[24A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[27A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[27A\u001b[2K\u001b[24A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[27A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[27A\u001b[2K\u001b[25A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2K\u001b[28A\u001b[2K\u001b[26A\u001b[2KEOF\n"
     ]
    }
   ],
   "source": [
    "! cd model-simple/container && sh build_and_push.sh {INFERENCE_ALGORITHM_NAME} Dockerfile-inference && cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Inference Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker_ssh_helper.wrapper import SSHModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "--------!"
     ]
    }
   ],
   "source": [
    "from sagemaker import Model\n",
    "\n",
    "import sagemaker as sage\n",
    "\n",
    "sess = sage.Session()\n",
    "\n",
    "# instance_type = \"ml.m5.xlarge\" # no GPU, will trigger an error\n",
    "# instance_type = \"ml.g4dn.xlarge\"\n",
    "instance_type = \"ml.p2.xlarge\"\n",
    "\n",
    "# endpoint_deployment_name = \"sm-gec-aws\"\n",
    "\n",
    "estimator = Model(\n",
    "    image_uri=IMAGE_URI_INFERENCE,\n",
    "    model_data=PRETRAINED_MODEL_DATA,\n",
    "    role=role,\n",
    "    source_dir=\"model-simple/container/gec\",\n",
    "    dependencies=[SSHModelWrapper.dependency_dir()],\n",
    "    entry_point=\"gec-simple-inference.py\",\n",
    "    sagemaker_session=sess,  # not local session anymore\n",
    "    #                   predictor_cls=None,\n",
    "    #                   env=None,\n",
    "    #                   name=None,\n",
    "    #                   vpc_config=None,\n",
    "    #                   enable_network_isolation=False,\n",
    "    #                   model_kms_key=None,\n",
    "    #                   image_config=None,\n",
    "    #                   code_location=None,\n",
    "    #                   container_log_level=20,\n",
    "    #                   dependencies=None,\n",
    "    #                   git_config=None\n",
    ")\n",
    "\n",
    "# ssh_wrapper = SSHEstimatorWrapper.create(estimator, connection_wait_time_seconds=0, local_user_id=local_user_id, log_to_stdout=True)\n",
    "\n",
    "ssh_wrapper = SSHModelWrapper.create(estimator, connection_wait_time_seconds=0)\n",
    "\n",
    "# deploy the model\n",
    "predictor = estimator.deploy(1, instance_type, endpoint_name=ENDPOINT_NAME, wait=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_ids = ssh_wrapper.get_instance_ids(timeout_in_sec=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GEC With Explanation - Inference Endpoint Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre trained NER model should be pickled and uploaded to the correct S3 bucket as a tarball. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "BUCKET = \"project-langbot-models\"\n",
    "KEY = \"gec_cows_l2h_small.gz\"\n",
    "PRETRAINED_MODEL_DATA = \"s3://{}/{}\".format(BUCKET, KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://project-langbot-models/gec_cows_l2h_small.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s3.Object(bucket_name='project-langbot-models', key='gec_cows_l2h_small.gz')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(PRETRAINED_MODEL_DATA)\n",
    "boto3.Session().resource(\"s3\").Bucket(BUCKET).Object(KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Based on\n",
      "# https://github.com/awslabs/amazon-sagemaker-examples/master/advanced_functionality/pytorch_extending_our_containers/pytorch_extending_our_containers.ipynb\n",
      "\n",
      "ARG REGION=us-west-2\n",
      "\n",
      "# SageMaker PyTorch image for INFERENCE\n",
      "FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/pytorch-inference:1.12.1-gpu-py38-cu113-ubuntu20.04-sagemaker\n",
      "\n",
      "ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      "\n",
      "# /opt/ml and all subdirectories are utilized by SageMaker, we use the /code subdirectory to store our user code.\n",
      "COPY /gec /opt/ml/code\n",
      "\n",
      "# this environment variable is used by the SageMaker PyTorch container to determine our user code directory.\n",
      "ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      "\n",
      "# this environment variable is used by the SageMaker PyTorch container to determine our program entry point\n",
      "# for training and serving.\n",
      "# For more information: https://github.com/aws/sagemaker-pytorch-container\n",
      "ENV SAGEMAKER_PROGRAM gec-inference.py\n",
      "\n",
      "RUN pip install --no-cache-dir --upgrade pip && \\\n",
      "    pip install --no-cache-dir numba==0.53.1 protobuf==3.20.* && pip install --no-cache-dir simpletransformers==0.64.3 nvgpu smdebug\n",
      "\n",
      "RUN pip freeze\n"
     ]
    }
   ],
   "source": [
    "!cat model1/container/Dockerfile-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Inference script - gec-inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "JSON_CONTENT_TYPE = \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "logger.setLevel(logging.DEBUG)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m====================== Running stuff ============================\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33minside model_fn, model_dir= \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel_dir\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    device = \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mDevice Type: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(device))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    model_loc = \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/gec_cows_l2h_small.pkl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m os.path.exists(model_loc):\u001b[37m\u001b[39;49;00m\n",
      "        logging.error(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mMissing model file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel_loc\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    model = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_loc, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:  \u001b[37m# open a text file\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        model = pickle.load(f) \u001b[37m# serialize the list\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# TODO: How to add GPU support for inferencing? Looks like NER model does not have .to() method.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#       Also do we need GPU for inference?\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# model.to(device)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logging.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mGEC model loaded into device \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mdevice\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(data, model):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mGot input Data: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mdata\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    prediction, _ = model.predict([data])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m prediction\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(serialized_input_data, content_type=JSON_CONTENT_TYPE):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mserialized_input_data object: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mserialized_input_data\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == JSON_CONTENT_TYPE:\u001b[37m\u001b[39;49;00m\n",
      "        input_data = json.loads(serialized_input_data)\u001b[37m\u001b[39;49;00m\n",
      "        logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33minput_data object: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00minput_data\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m input_data[\u001b[33m'\u001b[39;49;00m\u001b[33mline\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in Accept: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + content_type)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(prediction, content_type):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mprediction object before: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprediction\u001b[33m}\u001b[39;49;00m\u001b[33m, type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mtype\u001b[39;49;00m(prediction)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Transform predictions to JSON\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    prediction_result = {\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33moutput\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: prediction\u001b[37m\u001b[39;49;00m\n",
      "    }\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mprediction_result object: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprediction_result\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m prediction_result\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize container/gec/gec-inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Build and Push Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECR image fullname: 571667364805.dkr.ecr.us-west-2.amazonaws.com/sm-gec-aws:latest\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  17.92kB\n",
      "Step 1/8 : ARG REGION=us-west-2\n",
      "Step 2/8 : FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/pytorch-inference:1.12.1-gpu-py38-cu113-ubuntu20.04-sagemaker\n",
      " ---> cc486ae090f7\n",
      "Step 3/8 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> ed6c9f68b5de\n",
      "Step 4/8 : COPY /gec /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 923b5fcc86b5\n",
      "Step 5/8 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> fd25ac165e77\n",
      "Step 6/8 : ENV SAGEMAKER_PROGRAM gec-inference.py\n",
      " ---> Using cache\n",
      " ---> 58bc40662a62\n",
      "Step 7/8 : RUN pip install --no-cache-dir --upgrade pip &&     pip install --no-cache-dir numba==0.53.1 protobuf==3.20.* && pip install --no-cache-dir simpletransformers==0.64.3 nvgpu smdebug\n",
      " ---> Using cache\n",
      " ---> 27f4195ba81c\n",
      "Step 8/8 : RUN pip freeze\n",
      " ---> Using cache\n",
      " ---> ec46c7b89984\n",
      "Successfully built ec46c7b89984\n",
      "Successfully tagged sm-gec-aws:latest\n",
      "The push refers to repository [571667364805.dkr.ecr.us-west-2.amazonaws.com/sm-gec-aws]\n",
      "\n",
      "\u001b[1B74712a0c: Preparing \n",
      "\u001b[1B10414572: Preparing \n",
      "\u001b[1B37eeb897: Preparing \n",
      "\u001b[1B424ed6bf: Preparing \n",
      "\u001b[1Bb74bcd62: Preparing \n",
      "\u001b[1Bc6ec42e4: Preparing \n",
      "\u001b[1B44dc3edd: Preparing \n",
      "\u001b[1Ba78a3211: Preparing \n",
      "\u001b[1Bca7e3783: Preparing \n",
      "\u001b[1B07982a5f: Preparing \n",
      "\u001b[1B276eda72: Preparing \n",
      "\u001b[1Bb1b6f05e: Preparing \n",
      "\u001b[1B061b424e: Preparing \n",
      "\u001b[1B6e954844: Preparing \n",
      "\u001b[1B4676e227: Preparing \n",
      "\u001b[1B0fc30092: Preparing \n",
      "\u001b[1B8305c9a9: Preparing \n",
      "\u001b[1Bff3531fd: Preparing \n",
      "\u001b[1Bc617cad4: Preparing \n",
      "\u001b[1Bd6065936: Preparing \n",
      "\u001b[1Bf92cc97b: Preparing \n",
      "\u001b[1B0809d74c: Preparing \n",
      "\u001b[1Bf7fa3a1f: Preparing \n",
      "\u001b[1B4b2240de: Preparing \n",
      "\u001b[1Ba902ec50: Preparing \n",
      "\u001b[1B4828897a: Preparing \n",
      "\u001b[1B9aa8404f: Preparing \n",
      "\u001b[1B2b3d5595: Preparing \n",
      "\u001b[1B5186b826: Preparing \n",
      "\u001b[1B521d62fe: Preparing \n",
      "\u001b[1Bd36776dc: Preparing \n",
      "\u001b[1Bce4c0976: Preparing \n",
      "\u001b[1B7375cb04: Preparing \n",
      "\u001b[1B672e1e8b: Preparing \n",
      "\u001b[1B9e761223: Preparing \n",
      "\u001b[33B24ed6bf: Retrying in 1 second   [32A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[33A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[33A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[33A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[33A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[33A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[33A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[33A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2KEOF\n"
     ]
    }
   ],
   "source": [
    "! cd container && sh build_and_push.sh {INFERENCE_ALGORITHM_NAME} Dockerfile-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Inference Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "-------!"
     ]
    }
   ],
   "source": [
    "from sagemaker import Model\n",
    "\n",
    "import sagemaker as sage\n",
    "\n",
    "sess = sage.Session()\n",
    "\n",
    "# instance_type = \"ml.m5.xlarge\" # no GPU, will trigger an error\n",
    "# instance_type = \"ml.g4dn.xlarge\"\n",
    "instance_type = \"ml.p2.xlarge\"\n",
    "\n",
    "# endpoint_deployment_name = \"sm-gec-aws\"\n",
    "\n",
    "estimator = Model(\n",
    "    image_uri=IMAGE_URI_INFERENCE,\n",
    "    model_data=PRETRAINED_MODEL_DATA,\n",
    "    role=role,\n",
    "    source_dir=\"container/gec\",\n",
    "    entry_point=\"gec-inference.py\",\n",
    "    sagemaker_session=sess,  # not local session anymore\n",
    "    #                   predictor_cls=None,\n",
    "    #                   env=None,\n",
    "    #                   name=None,\n",
    "    #                   vpc_config=None,\n",
    "    #                   enable_network_isolation=False,\n",
    "    #                   model_kms_key=None,\n",
    "    #                   image_config=None,\n",
    "    #                   code_location=None,\n",
    "    #                   container_log_level=20,\n",
    "    #                   dependencies=None,\n",
    "    #                   git_config=None\n",
    ")\n",
    "\n",
    "# deploy the model\n",
    "predictor = estimator.deploy(1, instance_type, endpoint_name=ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2983/3261681033.py\", line 4, in <module>\n",
      "    response = sm_client.invoke_endpoint(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 535, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 963, in _make_api_call\n",
      "    http, parsed_response = self._make_request(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 986, in _make_request\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/endpoint.py\", line 119, in make_request\n",
      "    return self._send_request(request_dict, operation_model)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/endpoint.py\", line 199, in _send_request\n",
      "    success_response, exception = self._get_response(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/endpoint.py\", line 241, in _get_response\n",
      "    success_response, exception = self._do_get_response(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/endpoint.py\", line 281, in _do_get_response\n",
      "    http_response = self._send(request)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/endpoint.py\", line 377, in _send\n",
      "    return self.http_session.send(request)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/httpsession.py\", line 464, in send\n",
      "    urllib_response = conn.urlopen(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/http/client.py\", line 279, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/ssl.py\", line 1307, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/ssl.py\", line 1163, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "sm_client = sess.sagemaker_runtime_client\n",
    "# endpoint_name = \"sm-gec-aws\"\n",
    "response = sm_client.invoke_endpoint(\n",
    "    EndpointName=ENDPOINT_NAME,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps({\"line\":\"Hola Como estas?\"}),\n",
    ")\n",
    "\n",
    "r = response[\"Body\"]\n",
    "print(\"RESULT r.read().decode():\", r.read().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optional cleanup of the create endpoint\n",
    "The created endpoint can be deleted with the code below.\n",
    "\n",
    "This part represent the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '5c870347-dcb5-4c4f-9d5d-fa6fc62cb8f3',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '5c870347-dcb5-4c4f-9d5d-fa6fc62cb8f3',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Mon, 27 Nov 2023 00:03:29 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"sagemaker\")\n",
    "response = client.describe_endpoint_config(EndpointConfigName=ENDPOINT_NAME)\n",
    "model_name = response[\"ProductionVariants\"][0][\"ModelName\"]\n",
    "client.delete_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "# client.delete_endpoint_config(EndpointConfigName=ENDPOINT_NAME)\n",
    "# client.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
